{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-26T21:09:01.918145Z",
     "start_time": "2024-03-26T21:09:00.767413Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "global fig\n",
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "\n",
    "from skopt.utils import use_named_args, cook_initial_point_generator\n",
    "from skopt.space import Integer\n",
    "from skopt import gp_minimize\n",
    "\n",
    "########################\n",
    "### Custom functions ###\n",
    "########################\n",
    "from src.loss_func import DC, get_yield, hellinger_distance\n",
    "from src.phos_elect import create_grid, implant_grid, get_phosphenes\n",
    "### needed for matrix rotation/translation ect\n",
    "from src.ninimplant import get_xyz\n",
    "import src.utils as utils\n",
    "import src.visualizations as visualizations\n",
    "\n",
    "import src.generate_visual_sectors as gvs\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# added because: \"invalid value encountered in True-divide\"\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "CONFIG = utils.read_config(\"/home/odysseas/Desktop/UU/thesis/BayesianOpt/check_target_maps_10x10x10/config.json\")\n",
    "# determine range of parameters\n",
    "DIM1 = Integer(name='alpha', low=-90, high=90)  # visual degrees\n",
    "DIM2 = Integer(name='beta', low=-15, high=110)  # visual degrees - -15 is probably lowest possible angle, otherwise other hem is in the way if hem = RH -> low = -110, high = 15\n",
    "DIM3 = Integer(name='offset_from_base', low=0, high=40)     # in mm\n",
    "DIM4 = Integer(name='shank_length', low=10, high=20)    # in mm\n",
    "DIMENSIONS = [DIM1, DIM2, DIM3, DIM4]\n",
    "X0 = (CONFIG[\"INIT_ALPHA\"], CONFIG[\"INIT_BETA\"], CONFIG[\"INIT_OFFSET_FROM_BASE\"], CONFIG[\"INIT_SHANK_LENGTH\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T21:09:04.228653Z",
     "start_time": "2024-03-26T21:09:04.223702Z"
    }
   },
   "id": "58a553756f147b62",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@use_named_args(dimensions=DIMENSIONS)\n",
    "def f(alpha, beta, offset_from_base, shank_length):\n",
    "    \"\"\"This function encapsulates the electrode placement procedure and returns the cost value by\n",
    "    comparing the resulting phosphene map with the target map. By the design of skopt, it can\n",
    "    only take the objective function's parameters as arguments, so other variables used within\n",
    "    the function should be defined as global.\n",
    "\n",
    "    * First it creates a grid based on the four parameters.\n",
    "    * Phosphenes are generated based on the grid's contact points,\n",
    "      and their sizes are determined using cortical magnification and spread values.\n",
    "    * These phosphenes are converted into a 2D image representation.\n",
    "      The function then computes the dice coefficient and yield, and calculates\n",
    "      the Hellinger distance between the generated image and a target density.\n",
    "    * The resulting cost is a combination of these factors,\n",
    "      with penalties applied if the grid is invalid.\n",
    "    * The function also handles cases of invalid values and prints diagnostic information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    The decorators @use_named_args allows to call the function without\n",
    "    specifying the parameters, since dimensions is a list with the parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int or float\n",
    "        The calculated cost used by the bayesopt algorithm\n",
    "    \"\"\"\n",
    "    global CONFIG\n",
    "    # global variables defined in main\n",
    "    global start_location, gm_mask, target_density, bin_thresh\n",
    "    # global coordinates and maps from the mri scans defined in main\n",
    "    global good_coords, good_coords_V1, polar_map, ecc_map, sigma_map\n",
    "    # global variables related to the previous array\n",
    "    global iter_count, total_contacts_xyz_moved, valid_grids, overlap_valid_grids\n",
    "    global arr_current, optimized_arrays_from_f_manual\n",
    "    # cost functions\n",
    "    global arr_dices, total_dices, arr_yields, total_yields, arr_HDs, total_HDs, arr_costs, total_costs\n",
    "\n",
    "    grid_valid_overlap = True\n",
    "    penalty = 0.25\n",
    "    new_angle = (float(alpha), float(beta), 0)\n",
    "\n",
    "    # create grid\n",
    "    orig_grid = create_grid(start_location, shank_length, CONFIG[\"N_CONTACTPOINTS_SHANK\"], CONFIG[\"N_COMBS\"],\n",
    "                            CONFIG[\"N_SHANKS_PER_COMB\"], CONFIG[\"SPACING_ALONG_XY\"], offset_from_origin=0)\n",
    "\n",
    "    # implanting grid\n",
    "    all_output = implant_grid(gm_mask, orig_grid, start_location, new_angle, offset_from_base)\n",
    "    cur_contacts_xyz_moved, grid_valid_convex_hull = all_output[1], all_output[-1]\n",
    "\n",
    "    if arr_current <= 1:\n",
    "        new_contacts_xyz_moved = cur_contacts_xyz_moved\n",
    "        grid_valid = grid_valid_convex_hull\n",
    "    else:\n",
    "        new_contacts_xyz_moved = np.hstack((total_contacts_xyz_moved, cur_contacts_xyz_moved))\n",
    "        grid_valid_overlap = utils.get_overlap_validity(optimized_arrays_from_f_manual, cur_contacts_xyz_moved, CONFIG)\n",
    "        grid_valid = grid_valid_overlap and grid_valid_convex_hull\n",
    "\n",
    "    overlap_valid_grids.append(grid_valid_overlap)\n",
    "    valid_grids.append(grid_valid)\n",
    "\n",
    "    # get angle, ecc and rfsize for contactpoints (phosphenes[0-2][:] 0 angle x 1 ecc x 2 rfsize)\n",
    "    new_phosphenes_V1 = get_phosphenes(new_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "    array_phosphenes_V1 = get_phosphenes(cur_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "\n",
    "    phosphene_map = utils.get_phosphene_map(new_phosphenes_V1, CONFIG)\n",
    "    phosphene_map_array = utils.get_phosphene_map(array_phosphenes_V1, CONFIG)\n",
    "\n",
    "    # compute dice coefficient -> should be 1 -> invert cost\n",
    "    dice, im1, im2 = DC(target_density, phosphene_map_array, bin_thresh)\n",
    "    par1 = 1.0 - (CONFIG[\"A\"] * dice)\n",
    "    arr_dices.append(dice)\n",
    "\n",
    "    total_dice, _, _ = DC(target_density, phosphene_map, bin_thresh)\n",
    "    par1_total = 1.0 - (CONFIG[\"A\"] * total_dice)\n",
    "    total_dices.append(total_dice)\n",
    "\n",
    "    # compute yield -> should be 1 -> invert cost\n",
    "    grid_yield = get_yield(cur_contacts_xyz_moved, good_coords)\n",
    "\n",
    "    grid_yield_total = get_yield(new_contacts_xyz_moved, good_coords)\n",
    "    total_yields.append(grid_yield_total)\n",
    "\n",
    "    # compute hellinger distance -> should be small -> keep cost\n",
    "    hell_d = hellinger_distance(phosphene_map_array.flatten(), target_density.flatten())\n",
    "    hell_d_total = hellinger_distance(phosphene_map.flatten(), target_density.flatten())\n",
    "\n",
    "    if np.isnan(phosphene_map_array).any() or np.sum(phosphene_map_array) == 0:\n",
    "        par1 = 1\n",
    "\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if dice == 0.0 or np.isnan(phosphene_map).any() or np.sum(phosphene_map) == 0:\n",
    "        par1_total = 1\n",
    "\n",
    "    if np.isnan(hell_d) or np.isinf(hell_d):\n",
    "        par3 = 1\n",
    "    else:\n",
    "        par3 = CONFIG[\"C\"] * hell_d\n",
    "\n",
    "    if dice == 0 or par3 == 1:\n",
    "        grid_yield = 0\n",
    "    par2 = 1.0 - (CONFIG[\"B\"] * grid_yield)\n",
    "    arr_yields.append(grid_yield)\n",
    "\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if hell_d == 1.0 or np.isnan(hell_d_total) or np.isinf(hell_d_total):\n",
    "        par3_total = 1\n",
    "    else:\n",
    "        par3_total = CONFIG[\"C\"] * hell_d_total\n",
    "\n",
    "    arr_HDs.append(hell_d)\n",
    "    total_HDs.append(hell_d_total)\n",
    "\n",
    "    # combine cost functions\n",
    "    cost = par1 + par2 + par3\n",
    "    cost_total = par1_total + par2 + par3_total\n",
    "\n",
    "    # when some contact points are outside of the hemisphere (convex), add penalty\n",
    "    if not grid_valid:\n",
    "        cost = par1 + penalty + par2 + penalty + par3 + penalty\n",
    "        # always include the array specific yield\n",
    "        cost_total = par1_total + penalty + par2 + penalty + par3_total + penalty\n",
    "\n",
    "    # check if cost contains invalid value\n",
    "    if np.isnan(cost) or np.isinf(cost):\n",
    "        cost = 3\n",
    "\n",
    "    if np.isnan(cost_total) or np.isinf(cost_total):\n",
    "        cost_total = 3\n",
    "\n",
    "    arr_costs.append(cost)\n",
    "    total_costs.append(cost_total)\n",
    "\n",
    "    # print(f\"overlap valid: {grid_valid_overlap} / convex hull valid: {grid_valid_convex_hull} / \"\n",
    "    #       f\"cost: {cost} / total cost: {cost_total}\")\n",
    "    # print(f\"dice: {round(dice, 5)} / total dice: {round(total_dice, 5)} / yield: {round(grid_yield, 5)} / \"\n",
    "    #       f\"total yield: {round(grid_yield_total, 5)} / HD: {round(par3, 5)} / total HD: {round(par3_total, 5)}\", end=\"\\n\")\n",
    "\n",
    "    iter_count += 1\n",
    "    if iter_count % 25 == 0:\n",
    "        print(\"Now at iteration:\", iter_count, \"out of\", CONFIG[\"NUM_CALLS\"])\n",
    "\n",
    "    return cost_total\n",
    "\n",
    "def f_manual(alpha, beta, offset_from_base, shank_length, good_coords, good_coords_V1, target_density):\n",
    "    \"\"\"\n",
    "    Copy from f, to get phosphene map and contact points for the optimized parameters. Used to visualize results.\n",
    "    \"\"\"\n",
    "    global CONFIG\n",
    "    # global variables defined in main\n",
    "    global start_location, gm_mask, bin_thresh\n",
    "    # global coordinates and maps from the mri scans defined in main\n",
    "    global polar_map, ecc_map, sigma_map\n",
    "    # global variables related to the previous array\n",
    "    global iter_count, total_contacts_xyz_moved\n",
    "    global arr_current, optimized_arrays_from_f_manual\n",
    "    global best_dc, best_hd\n",
    "\n",
    "    penalty = 0.25\n",
    "    new_angle = (float(alpha), float(beta), 0)\n",
    "\n",
    "    # create grid\n",
    "    orig_grid = create_grid(start_location, shank_length, CONFIG[\"N_CONTACTPOINTS_SHANK\"], CONFIG[\"N_COMBS\"],\n",
    "                            CONFIG[\"N_SHANKS_PER_COMB\"], CONFIG[\"SPACING_ALONG_XY\"], offset_from_origin=0)\n",
    "\n",
    "    # implanting grid\n",
    "    ref_contacts_xyz, best_contacts_xyz_moved, refline, refline_moved, projection, ref_orig, ray_visualize, new_location, grid_valid_convex_hull = implant_grid(\n",
    "        gm_mask, orig_grid, start_location, new_angle, offset_from_base)\n",
    "\n",
    "    if arr_current <= 1:\n",
    "        new_contacts_xyz_moved = best_contacts_xyz_moved\n",
    "        grid_valid = grid_valid_convex_hull\n",
    "    else:\n",
    "        new_contacts_xyz_moved = np.hstack((total_contacts_xyz_moved, best_contacts_xyz_moved))\n",
    "        grid_valid_overlap = utils.get_overlap_validity(optimized_arrays_from_f_manual, best_contacts_xyz_moved, CONFIG)\n",
    "        grid_valid = grid_valid_overlap and grid_valid_convex_hull\n",
    "\n",
    "    # get angle, ecc and rfsize for contactpoints in each ROI (phosphenes[0-2][:] 0 angle x 1 ecc x 2 rfsize)\n",
    "    new_phosphenes_V1 = get_phosphenes(new_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "    array_phosphenes_V1 = get_phosphenes(best_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "\n",
    "    phosphene_map = utils.get_phosphene_map(new_phosphenes_V1, CONFIG)\n",
    "    phosphene_map_array = utils.get_phosphene_map(array_phosphenes_V1, CONFIG)\n",
    "\n",
    "    # compute dice coefficient -> should be large -> invert cost\n",
    "    arr_dice, im1, im2 = DC(target_density, phosphene_map_array, bin_thresh)\n",
    "\n",
    "    if not grid_valid or arr_dice == 0.0:\n",
    "        return [grid_valid, arr_dice]\n",
    "\n",
    "    total_dice, _, _ = DC(target_density, phosphene_map, bin_thresh)\n",
    "    par1_total = 1.0 - (CONFIG[\"A\"] * total_dice)\n",
    "\n",
    "    prop_total_dice = total_dice / best_dc\n",
    "\n",
    "    # compute yield -> should be 1 -> invert cost\n",
    "    arr_yield = get_yield(best_contacts_xyz_moved, good_coords)\n",
    "    total_yield = get_yield(new_contacts_xyz_moved, good_coords)\n",
    "\n",
    "    # compute Hellinger distance -> should be small -> keep cost\n",
    "    arr_hd = hellinger_distance(phosphene_map_array.flatten(), target_density.flatten())\n",
    "    total_hd = hellinger_distance(phosphene_map.flatten(), target_density.flatten())\n",
    "\n",
    "    prop_total_hd = (1 - total_hd) / (1 - best_hd)\n",
    "\n",
    "    ## validations steps\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if arr_dice == 0.0 or np.isnan(phosphene_map).any() or np.sum(phosphene_map) == 0:\n",
    "        par1_total = 1\n",
    "\n",
    "    if np.isnan(arr_hd) or np.isinf(arr_hd):\n",
    "        par3 = 1\n",
    "    else:\n",
    "        par3 = CONFIG[\"C\"] * arr_hd\n",
    "\n",
    "    if arr_dice == 0 or par3 == 1:\n",
    "        arr_yield = 0\n",
    "    par2 = 1.0 - (CONFIG[\"B\"] * arr_yield)\n",
    "\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if arr_hd == 1.0 or np.isnan(total_hd) or np.isinf(total_hd):\n",
    "        par3_total = 1\n",
    "    else:\n",
    "        par3_total = CONFIG[\"C\"] * total_hd\n",
    "\n",
    "    # combine cost functions\n",
    "    cost = par1_total + par2 + par3_total\n",
    "    best_cost = best_dc + 0 + best_hd\n",
    "    highest_cost = 3\n",
    "    # when some contact points are outside of the hemisphere (convex), add penalty\n",
    "    if not grid_valid:\n",
    "        cost = par1_total + penalty + par2 + penalty + par3_total + penalty\n",
    "\n",
    "    # check if cost contains invalid value\n",
    "    if np.isnan(cost) or np.isinf(cost):\n",
    "        cost = 3\n",
    "\n",
    "    # the proportion of the cost compared to the best possible cost\n",
    "    prop_cost = 1 - ((cost - best_cost) / (highest_cost - best_cost))\n",
    "\n",
    "    return [grid_valid, arr_dice, total_dice, prop_total_dice, arr_hd, total_hd, prop_total_hd, arr_yield, total_yield,\n",
    "            cost, prop_cost, array_phosphenes_V1, new_phosphenes_V1,\n",
    "            best_contacts_xyz_moved, phosphene_map_array, phosphene_map, new_contacts_xyz_moved]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T21:09:06.426576Z",
     "start_time": "2024-03-26T21:09:06.414841Z"
    }
   },
   "id": "a506b205ec662444",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"configuration:\\n\"\n",
    "      f\"{CONFIG['N_COMBS']} x {CONFIG['N_SHANKS_PER_COMB']} x {CONFIG['N_CONTACTPOINTS_SHANK']} for {CONFIG['NUM_CALLS']} iterations\")\n",
    "RESULTS_PATH = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/check_target_maps_10x10x10/results/\"\n",
    "# set file names\n",
    "FNAME_ANG = \"inferred_angle.mgz\"\n",
    "FNAME_ECC = \"inferred_eccen.mgz\"\n",
    "FNAME_SIGMA = \"inferred_sigma.mgz\"\n",
    "FNAME_APARC = \"aparc+aseg.mgz\"\n",
    "FNAME_LABEL = \"inferred_varea.mgz\"\n",
    "# lists of target maps to loop through\n",
    "TARGETS = ([gvs.upper_sector(windowsize=CONFIG[\"WINDOWSIZE\"], fwhm=800, radiusLow=0, radiusHigh=500, plotting=False),\n",
    "            gvs.lower_sector(windowsize=CONFIG[\"WINDOWSIZE\"], fwhm=800, radiusLow=0, radiusHigh=500, plotting=False),\n",
    "            gvs.inner_ring(windowsize=CONFIG[\"WINDOWSIZE\"], fwhm=400, radiusLow=0, radiusHigh=250, plotting=False),\n",
    "            gvs.complete_gauss(windowsize=CONFIG[\"WINDOWSIZE\"], fwhm=1200, radiusLow=0, radiusHigh=500, center=None, plotting=False)])\n",
    "\n",
    "TARGET_NAMES = ([\"upper_target\", \"lower_target\", \"inner_target\", \"full_target\"])\n",
    "def run(sub):\n",
    "    global start_location, gm_mask, target_density, bin_thresh\n",
    "    global arr_current, total_contacts_xyz_moved, optimized_arrays_from_f_manual\n",
    "    global overlap_valid_grids, valid_grids, iter_count\n",
    "    global good_coords, good_coords_V1, polar_map, ecc_map, sigma_map\n",
    "    # cost functions\n",
    "    global arr_dices, total_dices, arr_yields, total_yields, arr_HDs, total_HDs, arr_costs, total_costs\n",
    "    global best_dc, best_hd\n",
    "\n",
    "    dim1 = Integer(name='alpha', low=-90, high=90)  # visual degrees\n",
    "    # set beta angle range according to hemisphere\n",
    "    dim2_lh = Integer(name=\"beta\", low=-15, high=110)\n",
    "    dim2_rh = Integer(name=\"beta\", low=-110, high=15)\n",
    "    dim3 = Integer(name='offset_from_base', low=0, high=40)  # in mm\n",
    "    dim4 = Integer(name='shank_length', low=10, high=20)    # in mm\n",
    "    \n",
    "    for targ_name, target in zip(TARGET_NAMES, TARGETS):\n",
    "        target_density = target\n",
    "        print(f\"Now at {targ_name}\")\n",
    "    \n",
    "        target_density /= target_density.max()\n",
    "        target_density /= target_density.sum()\n",
    "        bin_thresh = np.percentile(target_density, CONFIG[\"DC_PERCENTILE\"])\n",
    "        data_dir = f\"/home/odysseas/Desktop/UU/thesis/BayesianOpt/input_processed_data_HCP/{sub}/T1w/mri/\"\n",
    "        if sub == \"fsaverage\":\n",
    "            data_dir = f\"/home/odysseas/Desktop/UU/thesis/BayesianOpt/input_processed_data_HCP/{sub}/\"\n",
    "    \n",
    "        # actually load data\n",
    "        ang_img = nib.load(data_dir + FNAME_ANG)\n",
    "        polar_map = ang_img.get_fdata()\n",
    "        ecc_img = nib.load(data_dir + FNAME_ECC)\n",
    "        ecc_map = ecc_img.get_fdata()\n",
    "        sigma_img = nib.load(data_dir + FNAME_SIGMA)\n",
    "        sigma_map = sigma_img.get_fdata()\n",
    "        aparc_img = nib.load(data_dir + FNAME_APARC)\n",
    "        aparc_roi = aparc_img.get_fdata()\n",
    "        label_img = nib.load(data_dir + FNAME_LABEL)\n",
    "        label_map = label_img.get_fdata()\n",
    "    \n",
    "        # compute valid voxels\n",
    "        dot = (ecc_map * polar_map)\n",
    "        good_coords = np.asarray(np.where(dot != 0.0))\n",
    "    \n",
    "        # filter gm per hemisphere\n",
    "        cs_coords_rh = np.where(aparc_roi == 1021)\n",
    "        cs_coords_lh = np.where(aparc_roi == 2021)\n",
    "        gm_coords_rh = np.vstack(np.where((aparc_roi >= 1000) & (aparc_roi < 2000)))\n",
    "        gm_coords_lh = np.vstack(np.where(aparc_roi > 2000))\n",
    "        xl, yl, zl = get_xyz(gm_coords_lh)\n",
    "        xr, yr, zr = get_xyz(gm_coords_rh)\n",
    "        gm_lh = np.array([xl, yl, zl]).T\n",
    "        gm_rh = np.array([xr, yr, zr]).T\n",
    "    \n",
    "        # extract labels\n",
    "        v1_coords_rh = np.asarray(np.where(label_map == 1))\n",
    "        v1_coords_lh = np.asarray(np.where(label_map == 1))\n",
    "    \n",
    "        set_rounded_good_coords = set(map(tuple, good_coords.T))\n",
    "        set_rounded_gm_coords_rh = set(map(tuple, gm_coords_rh.T))\n",
    "        set_rounded_gm_coords_lh = set(map(tuple, gm_coords_lh.T))\n",
    "        set_rounded_v1_coords_lh = set(map(tuple, v1_coords_lh.T))\n",
    "        set_rounded_v1_coords_rh = set(map(tuple, v1_coords_rh.T))\n",
    "    \n",
    "        # divide V1 coords per hemisphere\n",
    "        good_coords_lh = np.array(list(set(set_rounded_good_coords) & set(set_rounded_gm_coords_lh))).T\n",
    "        good_coords_rh = np.array(list(set(set_rounded_good_coords) & set(set_rounded_gm_coords_rh))).T\n",
    "        v1_coords_lh = np.array(list(set(set_rounded_v1_coords_lh) & set(set_rounded_gm_coords_lh))).T\n",
    "        v1_coords_rh = np.array(list(set(set_rounded_v1_coords_rh) & set(set_rounded_gm_coords_rh))).T\n",
    "    \n",
    "        # find center of left and right calcarine sulci\n",
    "        median_lh = [np.median(cs_coords_lh[0][:]), np.median(cs_coords_lh[1][:]), np.median(cs_coords_lh[2][:])]\n",
    "        median_rh = [np.median(cs_coords_rh[0][:]), np.median(cs_coords_rh[1][:]), np.median(cs_coords_rh[2][:])]\n",
    "    \n",
    "        # get GM mask and compute dorsal/posterior planes\n",
    "        gm_mask = np.where(aparc_roi != 0)\n",
    "    \n",
    "        # apply optimization to each hemisphere\n",
    "        for gm_mask, hem, start_location, good_coords, good_coords_V1, dim2 in zip([gm_lh, gm_rh], [\"LH\", \"RH\"],\n",
    "                                                                                   [median_lh, median_rh],\n",
    "                                                                                   [good_coords_lh, good_coords_rh],\n",
    "                                                                                   [v1_coords_lh, v1_coords_rh],\n",
    "                                                                                   [dim2_lh, dim2_rh]):\n",
    "    \n",
    "            print(f\"SUBJECT {sub}, HEMISPHERE {hem}\")\n",
    "            sub_target = sub + \"_\" + targ_name\n",
    "            utils.create_dirs(RESULTS_PATH, sub_target, hem)\n",
    "    \n",
    "            best_possible_phos = get_phosphenes(good_coords_V1, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "            best_possible_map = utils.get_phosphene_map(best_possible_phos, CONFIG)\n",
    "    \n",
    "            best_dc, _, _ = DC(target_density, best_possible_map, bin_thresh)\n",
    "            best_hd = hellinger_distance(best_possible_map.flatten(), target_density.flatten())\n",
    "    \n",
    "            total_contacts_xyz_moved = None\n",
    "            all_phosphenes = None\n",
    "            total_phosphene_map = None\n",
    "            optimized_arrays_from_f_manual = {}\n",
    "            phosphenes_per_arr = {}\n",
    "            phosphene_map_per_arr = {}\n",
    "            out_df_all_results = pd.DataFrame()\n",
    "            out_df_best_results = pd.DataFrame()\n",
    "            dimensions = [dim1, dim2, dim3, dim4]\n",
    "            # global arr_current\n",
    "            arr_current = 1\n",
    "            for i in range(1, CONFIG[\"N_ARRAYS\"] + 1):\n",
    "                print(f\"NOW WORKING ON ARRAY {i} OUT OF {CONFIG['N_ARRAYS']} for {sub_target}, {hem}, \"\n",
    "                      f\"AND VALID ONES SO FAR ARE {len(optimized_arrays_from_f_manual)}\")\n",
    "    \n",
    "                arr_dices, total_dices = [], []\n",
    "                arr_yields, total_yields = [], []\n",
    "                arr_HDs, total_HDs = [], []\n",
    "                arr_costs, total_costs = [], []\n",
    "    \n",
    "                iter_count = 1\n",
    "                valid_grids = []\n",
    "                overlap_valid_grids = []\n",
    "    \n",
    "                # create initial point generator\n",
    "                lhs2 = cook_initial_point_generator(\"lhs\", criterion=\"maximin\")\n",
    "    \n",
    "                # optimize\n",
    "                print(\"Starting iteration: 1\")\n",
    "                res = gp_minimize(f, x0=X0, dimensions=dimensions, n_jobs=1, n_calls=CONFIG[\"NUM_CALLS\"],\n",
    "                                  n_initial_points=CONFIG[\"NUM_INITIAL_POINTS\"], initial_point_generator=lhs2,\n",
    "                                  callback=[utils.custom_stopper])\n",
    "    \n",
    "                best_params_list = [res.x[0], res.x[1], res.x[2], res.x[3]]\n",
    "    \n",
    "                # print results\n",
    "                print(\"subject \", sub_target, \" \", hem)\n",
    "    \n",
    "                # the final array coordinates are contacts_xyz_moved\n",
    "                data = f_manual(res.x[0], res.x[1], res.x[2], res.x[3], good_coords, good_coords_V1, target_density)\n",
    "                grid_valid, arr_dice = data[0], data[1]\n",
    "    \n",
    "                print(f\"The best configuration for array {i} is {'valid' if grid_valid else 'invalid'}\")\n",
    "                if not grid_valid or arr_dice == 0.0:\n",
    "                    print(f\"should skip array {i} because it is invalid or phosphene map is empty\")\n",
    "                    continue\n",
    "    \n",
    "                (total_dice, prop_total_dice, arr_hd, total_hd, prop_total_hd, arr_yield, total_yield,\n",
    "                 cost, prop_cost, arr_phosphenes, all_phosphenes, contacts_xyz_moved,\n",
    "                 arr_phosphene_map, total_phosphene_map, total_contacts_xyz_moved) = data[2:]\n",
    "    \n",
    "                optimized_arrays_from_f_manual[arr_current] = contacts_xyz_moved\n",
    "                phosphenes_per_arr[arr_current] = arr_phosphenes\n",
    "                phosphene_map_per_arr[arr_current] = arr_phosphene_map\n",
    "                # print(\"best dice, best total dice, best yield, best total yield, best total cost:\", arr_dice,\n",
    "                #       total_dice, arr_yield, total_yield, cost)\n",
    "                # print(\"best HD, best total HD:\", arr_hd, total_hd)\n",
    "                # print(\"prop total dice, prop total hd, prop cost\", prop_total_dice, prop_total_hd, prop_cost)\n",
    "    \n",
    "                visualizations.visualize_array_map(arr_phosphene_map, total_phosphene_map, hem)\n",
    "                print(\"*\" * 35)\n",
    "                print(\"FINISHED ARRAY\", arr_current)\n",
    "                print(\"*\" * 35)\n",
    "    \n",
    "                df_arr = utils.get_arr_df(arr_current, arr_dices, total_dices, arr_yields, total_yields, arr_HDs,\n",
    "                                    total_HDs, arr_costs, total_costs, CONFIG[\"NUM_CALLS\"])\n",
    "                df_best = utils.get_best_df_10x10x10(arr_current, arr_dice, total_dice, prop_total_dice, arr_yield, total_yield,\n",
    "                                      arr_hd, total_hd, prop_total_hd, cost, prop_cost, best_params_list)\n",
    "\n",
    "                out_df_all_results = pd.concat([out_df_all_results, df_arr], axis=0, ignore_index=True)\n",
    "                out_df_best_results = pd.concat([out_df_best_results, df_best], axis=0, ignore_index=True)\n",
    "                arr_current += 1\n",
    "\n",
    "            pickle_data = [optimized_arrays_from_f_manual, phosphenes_per_arr, phosphene_map_per_arr,\n",
    "                           total_contacts_xyz_moved, all_phosphenes, total_phosphene_map]\n",
    "\n",
    "            utils.write_results(out_df_all_results, RESULTS_PATH, sub_target, hem, \"all\")\n",
    "            utils.write_results(out_df_best_results, RESULTS_PATH, sub_target, hem, \"best\")\n",
    "\n",
    "            utils.write_results_pickle(RESULTS_PATH, sub_target, hem, pickle_data)\n",
    "            utils.write_params(RESULTS_PATH, sub_target, hem, CONFIG)\n",
    "    \n",
    "            # visualize and save maps\n",
    "            visualizations.visualize_phosphene_maps(phosphene_map_per_arr, total_phosphene_map, RESULTS_PATH, sub_target, hem, CONFIG, show=False, save=True)\n",
    "            visualizations.visualize_polar_plot(all_phosphenes, RESULTS_PATH, sub_target, hem, CONFIG, show=False, save=True)\n",
    "            visualizations.visualize_kde_polar_plot(all_phosphenes, RESULTS_PATH, sub_target, hem, CONFIG, show=False, save=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T21:09:54.069781Z",
     "start_time": "2024-03-26T21:09:53.947809Z"
    }
   },
   "id": "b6b9cb09c5653c01",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "subj_list = os.listdir(\"/home/odysseas/Desktop/UU/thesis/BayesianOpt/input_processed_data_HCP/\")\n",
    "sub = random.choice(subj_list)\n",
    "run(sub)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T21:16:02.864176Z",
     "start_time": "2024-03-26T21:10:12.318126Z"
    }
   },
   "id": "ced1c478a774db56",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def read_pickle_file(sub: str, hem: str) -> list:\n",
    "    \"\"\"Reads the saved pickle file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hem : str\n",
    "        The hemisphere from which we want to get the pickle file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : list\n",
    "        [optimized_arrays_from_f_manual, phosphenes_per_arr, phosphene_map_per_arr,\n",
    "        total_contacts_xyz_moved, all_phosphenes, total_phosphene_map]\n",
    "    \"\"\"\n",
    "    import glob, pickle\n",
    "    RESULTS_PATH = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/fsaverage_5_arrays_10x10x10/results/\"\n",
    "    dir = RESULTS_PATH + sub + \"/\" + hem + \"/\"\n",
    "    filenames = glob.glob(os.path.join(dir, \"*.pkl\"))\n",
    "    data = []\n",
    "    if filenames:\n",
    "        # Assuming there's only one file in the directory, you can take the first one\n",
    "        filename = filenames[0]\n",
    "        try:\n",
    "            with open(filename, \"rb\") as file:\n",
    "                data = pickle.load(file)\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "        return data\n",
    "\n",
    "data = read_pickle_file(\"100610\", \"LH\")\n",
    "all_phosphenes = data[4]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:29:33.434622Z",
     "start_time": "2024-03-26T17:29:33.425664Z"
    }
   },
   "id": "5543f9dde673b872",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "457c800996638455",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
