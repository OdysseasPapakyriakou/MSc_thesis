{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T13:06:43.838688Z",
     "start_time": "2024-04-13T13:06:43.836870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import ttest_rel"
   ],
   "id": "f33266f57897bf52",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T13:06:50.473084Z",
     "start_time": "2024-04-13T13:06:50.462342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_df_for_descr_ind_avg(max_arrays: int) -> pd.DataFrame:\n",
    "    \"\"\"Reads the data for all subjects and from both the individual and the average approach.\n",
    "    It selects the array that is specified in max_arrays, if it exists. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    max_arrays : int\n",
    "        The maximum number of arrays to read.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out_df : pd.DataFrame\n",
    "        A dataframe used for descriptive stats:\n",
    "        [\"subject\", \"method\", \"hemisphere\", \"array\", \"total_dice\", \"prop_total_dice\", \n",
    "        \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "    \"\"\"\n",
    "    methods = [\"ind\", \"avg\"]\n",
    "    \n",
    "    ind_path = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/5_arrays_10x10x10/results/\"\n",
    "    avg_path = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/fsaverage_5_arrays_10x10x10/results/\"\n",
    "    results_paths = [ind_path, avg_path]\n",
    "    \n",
    "    ind_subs = os.listdir(ind_path)\n",
    "    avg_subs = os.listdir(avg_path)\n",
    "    subs_lists = [ind_subs, avg_subs]\n",
    "    out_df = pd.DataFrame()\n",
    "    arrays = [i for i in range(1, max_arrays + 1)]\n",
    "    for sub_list, sub_path, method in zip(subs_lists, results_paths, methods):\n",
    "        if \"exp\" in sub_list:\n",
    "            sub_list.remove(\"exp\")\n",
    "        if \"fsaverage\" in sub_list:\n",
    "            sub_list.remove(\"fsaverage\")\n",
    "        for sub in sub_list:\n",
    "            for hem in [\"LH\", \"RH\"]:\n",
    "                hem_dir = os.path.join(sub_path, sub, hem)\n",
    "                filenames = glob.glob(os.path.join(hem_dir, \"*.csv\"))\n",
    "                # Assuming there's only one file in the directory, you can take the first one\n",
    "                filename = [file for file in filenames if \"best\" in file][0]\n",
    "                \n",
    "                res_df = pd.read_csv(filename)        \n",
    "                columns_to_select = [\"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                \n",
    "                max_array_exists = arrays[-1] in res_df[\"array\"].tolist()\n",
    "                if max_array_exists:\n",
    "                    for array in arrays:\n",
    "                        arr_row = res_df[res_df[\"array\"] == array]\n",
    "                        selected_columns = arr_row[columns_to_select].copy()\n",
    "                        selected_columns[\"subject\"] = sub\n",
    "                        selected_columns[\"hemisphere\"] = hem\n",
    "                        selected_columns[\"method\"] = method\n",
    "                        column_order = [\"subject\", \"method\", \"hemisphere\", \"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                        selected_columns = selected_columns[column_order]\n",
    "                        out_df = pd.concat([out_df, selected_columns], ignore_index=True)\n",
    "    return out_df\n",
    "\n",
    "def create_df_for_ind_vs_avg() -> pd.DataFrame:\n",
    "    \"\"\"Reads the data for all subjects and from both the individual and the average approach.\n",
    "    It selects the last array placed, regardless of its number or whether the same array\n",
    "    was placed in the other hemisphere as well. \n",
    "    So in total it has (subs x hems x methods) = (181 x 2 x 2) = 724 rows\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out_df : pd.DataFrame\n",
    "        A dataframe to be put in the AnovaRM function with columns:\n",
    "        [\"subject\", \"hemisphere\", \"method\", \"max_array\", \"total_dice\", \"prop_total_dice\", \n",
    "        \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "    \"\"\"\n",
    "    methods = [\"ind\", \"avg\"]\n",
    "    \n",
    "    ind_path = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/5_arrays_10x10x10/results/\"\n",
    "    avg_path = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/fsaverage_5_arrays_10x10x10/results/\"\n",
    "    results_paths = [ind_path, avg_path]\n",
    "    \n",
    "    ind_subs = os.listdir(ind_path)\n",
    "    avg_subs = os.listdir(avg_path)\n",
    "    subs_lists = [ind_subs, avg_subs]\n",
    "    out_df = pd.DataFrame()\n",
    "    \n",
    "    for sub_list, sub_path, method in zip(subs_lists, results_paths, methods):\n",
    "        if \"exp\" in sub_list:\n",
    "            sub_list.remove(\"exp\")\n",
    "        if \"fsaverage\" in sub_list:\n",
    "            sub_list.remove(\"fsaverage\")\n",
    "    \n",
    "        for sub in sub_list:\n",
    "            for hem in [\"LH\", \"RH\"]:\n",
    "                hem_dir = os.path.join(sub_path, sub, hem)\n",
    "                filenames = glob.glob(os.path.join(hem_dir, \"*.csv\"))\n",
    "                # Assuming there's only one file in the directory, you can take the first one\n",
    "                filename = [file for file in filenames if \"best\" in file][0]\n",
    "                try:\n",
    "                    res_df = pd.read_csv(filename)\n",
    "                    res_df = res_df.iloc[-1:]    # select max array (the last row)\n",
    "            \n",
    "                    columns_to_select = [\"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                    selected_columns = res_df[columns_to_select].copy()\n",
    "                    selected_columns[\"subject\"] = sub\n",
    "                    selected_columns[\"hemisphere\"] = hem\n",
    "                    selected_columns[\"method\"] = method\n",
    "                    column_order = [\"subject\", \"hemisphere\", \"method\", \"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                    selected_columns = selected_columns[column_order]\n",
    "                    out_df = pd.concat([out_df, selected_columns], ignore_index=True)\n",
    "                except FileNotFoundError as e:\n",
    "                    print(f\"File {filename} not found\")\n",
    "                    continue\n",
    "    out_df.rename(columns={\"array\": \"max_array\"}, inplace=True)\n",
    "    return out_df"
   ],
   "id": "d66f78572b9e8bcb",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T13:45:39.894938Z",
     "start_time": "2024-04-13T13:45:39.861475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def violin_plots_all(results_df: pd.DataFrame) -> None:\n",
    "    \"\"\"Creates violin plots for the cost function, given the df from create_df_for_ind_vs_avg().\n",
    "    This df considers all 181 subjects from both hemispheres and methods and contains\n",
    "    the last validly placed array.\"\"\"\n",
    "    total_observations = len(results_df.subject.unique())\n",
    "    res_df = results_df.copy()\n",
    "    res_df[\"total_dice_loss\"] = 1 - res_df[\"total_dice\"]\n",
    "    res_df[\"array_yield_loss\"] = 1 - res_df[\"array_yield\"]\n",
    "    dvs = [\"cost\", \"total_dice_loss\", \"array_yield_loss\", \"total_HD\"]\n",
    "    dv_names = [\"Cost\", \"Dice loss (1-dice)\", \"Yield loss (1-yield)\", \"Hellinger distance\"]\n",
    "    # yield is not meaningful because it's only for the last validly placed array\n",
    "    dvs.remove(\"array_yield_loss\")\n",
    "    dv_names.remove(\"Yield loss (1-yield)\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(dvs), figsize=(16, 8), sharex=True)\n",
    "    for i, dv in enumerate(dvs):\n",
    "        sns.violinplot(data=res_df, x=\"method\", y=dv, hue=\"hemisphere\", inner=\"box\", split=True, ax=axes[i], order=[\"ind\", \"avg\"])\n",
    "        axes[i].legend(title=\"hemisphere\", labels=[\"LH\", \"RH\"], handles=axes[i].legend_.legend_handles)\n",
    "        axes[i].set_title(f\"{dv_names[i]} per method\", fontsize=16)\n",
    "        axes[i].set_xlabel(\"\", fontsize=16)\n",
    "        axes[i].set_ylabel(dv_names[i], fontsize=16)\n",
    "        axes[i].tick_params(axis=\"x\", labelsize=16)\n",
    "    fig.suptitle(f\"Mean losses per method (based on the last validly placed array) for all {total_observations} subjects\", fontsize=24)\n",
    "    fig.supxlabel(\"Method\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./losses_violin_plots.png\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def visualize_yield_loss(ind_descriptives: pd.DataFrame, avg_descriptives: pd.DataFrame) -> None:\n",
    "    \"\"\"Creates and saves a plot for the yield loss.\"\"\"\n",
    "    ind_descriptives[\"method\"] = [\"ind\"] * len(ind_descriptives)\n",
    "    avg_descriptives[\"method\"] = [\"avg\"] * len(avg_descriptives)\n",
    "    df = pd.concat([ind_descriptives, avg_descriptives], ignore_index=True, axis=0)\n",
    "\n",
    "    g = sns.catplot(data=df, x=\"method\", y=\"array_yield_loss\", hue=\"hemisphere\", \n",
    "                    col=\"array\", kind=\"bar\", errorbar=\"sd\", sharex=True, legend=False)\n",
    "    plt.suptitle(\"Mean yield loss per method, array, and hemisphere\", fontsize=28)\n",
    "    plt.subplots_adjust(top=0.8)\n",
    "    i = 0\n",
    "    for ax, col in zip(g.axes.flatten(), df[\"array\"].unique()):\n",
    "        ax.set_ylabel(\"Array yield loss\", fontsize=24)\n",
    "        ax.set_xlabel(\"\")\n",
    "        if i == 2:\n",
    "            ax.set_xlabel(\"Method\", fontsize=24)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=20)\n",
    "        ax.set_title(f\"array {col}\", fontsize=20)\n",
    "        i += 1\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1.35), loc=\"upper right\", title=\"hemisphere\",borderaxespad=0., frameon=False, fontsize=\"xx-large\", title_fontsize=\"xx-large\")\n",
    "    plt.savefig(\"./yield_losses_exp2.png\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def create_histograms(data: pd.DataFrame) -> None:\n",
    "    \"\"\"Creates and saves histograms of the cost function by hemisphere and method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The dataframe generated by create_df_for_ind_vs_avg()\n",
    "    \"\"\"\n",
    "    data_LH = data[data.hemisphere == \"LH\"]\n",
    "    data_RH = data[data.hemisphere == \"RH\"]\n",
    "    row = 0\n",
    "    col = 0\n",
    "    colors = [\"green\", \"skyblue\"]\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    for hem, df in zip([\"left\", \"right\"], [data_LH, data_RH]):\n",
    "        for method, method_name in zip([\"ind\", \"avg\"], [\"individual\", \"average\"]):\n",
    "            method_df = df[df[\"method\"] == method].reset_index(drop=True).copy()\n",
    "            sns.histplot(data=method_df, x=\"cost\", kde=False, color=colors[col], ax=axes[row, col])\n",
    "            axes[row, col].set_xlabel(f\"Cost for {method_name} method\", fontsize=14) if row == 1 else axes[row, col].set_xlabel(\"\")\n",
    "            axes[row, col].set_ylabel(\"\")\n",
    "            col += 1\n",
    "        row += 1\n",
    "        col = 0\n",
    "    \n",
    "    labels = [\"Count for left hemisphere\", \"Count for right hemisphere\"]\n",
    "    for l, ax in zip(labels, axes):\n",
    "        ax[0].set_ylabel(l, fontsize=14)\n",
    "        \n",
    "    fig.suptitle(f\"Distribution of cost per method and hemisphere\", fontsize=24)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./histograms_exp2.png\")\n",
    "    plt.show()\n",
    "\n",
    "def get_descriptive_stats(all_arrays_df: list, method: str, hem: str) -> pd.DataFrame:\n",
    "    \"\"\"Gets descriptive statistics for the given methodology and hemisphere.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    all_arrays_df : list\n",
    "        A list with all dataframes (one dataframe for each max array considered).\n",
    "        The dataframes are created using create_df_for_descr_ind_avg(max_arrays).\n",
    "    method : str\n",
    "        The methodology, one of \"ind\", \"avg\"\n",
    "    hem : str\n",
    "        The hemisphere, one of \"LH\", \"RH\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    descriptive_stats_df : pd.DataFrame\n",
    "        A dataframe with descriptive statistics for the given method and hemisphere, one row for each array.\n",
    "        So it describes how many subs completed that array, with the average values.\n",
    "    \"\"\"\n",
    "    descriptive_stats_df = pd.DataFrame()\n",
    "    for df in all_arrays_df:\n",
    "        method_hem_df = df[(df.method == method) & (df.hemisphere == hem)]\n",
    "        max_array = method_hem_df.array.max()\n",
    "        total_subs = len(method_hem_df.subject.unique())\n",
    "        stats = method_hem_df.groupby([\"hemisphere\", \"array\"])[\n",
    "            [\"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\",\n",
    "             \"prop_cost\"]].mean().reset_index()\n",
    "        stats = stats[stats[\"array\"] == max_array].reset_index(drop=True)\n",
    "        stats[\"total_subjects\"] = total_subs\n",
    "        stats[\"total_dice_loss\"] = 1 - stats[\"total_dice\"]\n",
    "        stats[\"array_yield_loss\"] = 1 - stats[\"array_yield\"]\n",
    "        column_order = [\"array\", \"hemisphere\", \"total_subjects\", \"total_dice_loss\", \"prop_total_dice\",\n",
    "                        \"array_yield_loss\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "        stats = stats[column_order]\n",
    "        descriptive_stats_df = pd.concat([descriptive_stats_df, stats], ignore_index=True)\n",
    "\n",
    "    return descriptive_stats_df\n",
    "\n",
    "def get_mean_std(data: pd.DataFrame) -> None:\n",
    "    \"\"\"Prints the mean and standard deviation of the data by method and hemisphere.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The dataframe generated by create_df_for_ind_vs_avg()\n",
    "    \"\"\"\n",
    "    data_LH = data[data.hemisphere == \"LH\"]\n",
    "    data_RH = data[data.hemisphere == \"RH\"]\n",
    "    ind_LH = data_LH[data_LH[\"method\"] == \"ind\"]\n",
    "    avg_LH = data_LH[data_LH[\"method\"] == \"avg\"]\n",
    "    ind_RH = data_RH[data_RH[\"method\"] == \"ind\"]\n",
    "    avg_RH = data_RH[data_RH[\"method\"] == \"avg\"]\n",
    "    all_dfs = [ind_LH, avg_LH, ind_RH, avg_RH]\n",
    "    names = [\"ind_LH\", \"avg_LH\", \"ind_RH\", \"avg_RH\"]\n",
    "    for name, df in zip(names, all_dfs):\n",
    "        mean = df[\"cost\"].mean()\n",
    "        std = df[\"cost\"].std()\n",
    "        print(f\"data: {name}, mean: {mean}, std: {std}\")\n",
    "        \n",
    "def run_paired_ttest(data: pd.DataFrame, dv: str) -> None:\n",
    "    \"\"\"Runs and prints two paired samples t-tests. One for each hemisphere. \n",
    "    The within subjects factor is the methodology and the dv is the cost.\n",
    "    The alternative hypothesis is one-sided: individual < average\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The dataframe generated by create_df_for_ind_vs_avg()\n",
    "    \"\"\"\n",
    "    data_LH = data[data.hemisphere == \"LH\"]\n",
    "    data_RH = data[data.hemisphere == \"RH\"]\n",
    "    ind_LH = data_LH[data_LH[\"method\"] == \"ind\"]\n",
    "    avg_LH = data_LH[data_LH[\"method\"] == \"avg\"]\n",
    "    ind_RH = data_RH[data_RH[\"method\"] == \"ind\"]\n",
    "    avg_RH = data_RH[data_RH[\"method\"] == \"avg\"]\n",
    "    print(ttest_rel(ind_LH[dv], avg_LH[dv], alternative=\"less\"))\n",
    "    print(ttest_rel(ind_RH[dv], avg_RH[dv], alternative=\"less\"))"
   ],
   "id": "85a5233fcd010627",
   "execution_count": 74,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T13:09:40.474257Z",
     "start_time": "2024-04-13T13:09:28.983265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ind_avg_hem_arr1 = create_df_for_descr_ind_avg(max_arrays=1)\n",
    "ind_avg_hem_arr2 = create_df_for_descr_ind_avg(max_arrays=2)\n",
    "ind_avg_hem_arr3 = create_df_for_descr_ind_avg(max_arrays=3)\n",
    "ind_avg_hem_arr4 = create_df_for_descr_ind_avg(max_arrays=4)\n",
    "ind_avg_hem_arr5 = create_df_for_descr_ind_avg(max_arrays=5)\n",
    "ind_avg_list_all_array_dfs = [ind_avg_hem_arr1, ind_avg_hem_arr2, ind_avg_hem_arr3, ind_avg_hem_arr4, ind_avg_hem_arr5]"
   ],
   "id": "f4cc89fb8e463c09",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T17:01:56.662658Z",
     "start_time": "2024-04-09T17:01:56.657128Z"
    }
   },
   "cell_type": "code",
   "source": "ind_avg_hem_arr5.head()",
   "id": "71b5287dbc79540a",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T17:09:47.148701Z",
     "start_time": "2024-04-09T17:09:47.142716Z"
    }
   },
   "cell_type": "code",
   "source": "ind_avg_list_all_array_dfs[0].head()",
   "id": "ac6f4148649b4aa2",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T13:26:59.167585Z",
     "start_time": "2024-04-13T13:26:59.096540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ind_descriptives_LH = get_descriptive_stats(ind_avg_list_all_array_dfs, \"ind\", \"LH\")\n",
    "ind_descriptives_RH = get_descriptive_stats(ind_avg_list_all_array_dfs, \"ind\", \"RH\")\n",
    "avg_descriptives_LH = get_descriptive_stats(ind_avg_list_all_array_dfs, \"avg\", \"LH\")\n",
    "avg_descriptives_RH = get_descriptive_stats(ind_avg_list_all_array_dfs, \"avg\", \"RH\")\n",
    "ind_descriptives = pd.concat([ind_descriptives_LH, ind_descriptives_RH], axis=0)\n",
    "avg_descriptives = pd.concat([avg_descriptives_LH, avg_descriptives_RH], axis=0)"
   ],
   "id": "f5c13228a40bf1c7",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:51:50.855331Z",
     "start_time": "2024-04-10T16:51:50.849404Z"
    }
   },
   "cell_type": "code",
   "source": "avg_descriptives_LH",
   "id": "3af9a91659defe34",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:51:53.466451Z",
     "start_time": "2024-04-10T16:51:53.460015Z"
    }
   },
   "cell_type": "code",
   "source": "avg_descriptives_RH",
   "id": "9e33f41da49ca8b8",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T19:31:57.128342Z",
     "start_time": "2024-04-10T19:31:55.881230Z"
    }
   },
   "cell_type": "code",
   "source": "data = create_df_for_ind_vs_avg()",
   "id": "39cb714b09306b46",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:51:59.855363Z",
     "start_time": "2024-04-10T16:51:59.848624Z"
    }
   },
   "cell_type": "code",
   "source": "data.groupby([\"method\", \"hemisphere\", \"max_array\"])[[\"subject\"]].count()",
   "id": "b91ae78fb9ddc84b",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T19:41:29.277124Z",
     "start_time": "2024-04-10T19:41:28.720006Z"
    }
   },
   "cell_type": "code",
   "source": "violin_plots_all(data)",
   "id": "e5f42c7863bffb63",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-13T14:31:48.981409Z",
     "start_time": "2024-04-13T14:31:48.294164Z"
    }
   },
   "cell_type": "code",
   "source": "visualize_yield_loss(ind_descriptives, avg_descriptives)",
   "id": "12dd0f5d3bbf3e19",
   "execution_count": 193,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T19:36:06.233547Z",
     "start_time": "2024-04-10T19:36:06.229040Z"
    }
   },
   "cell_type": "code",
   "source": "get_mean_std(data)",
   "id": "6492adedbfd870da",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T17:02:02.587099Z",
     "start_time": "2024-04-10T17:02:02.577314Z"
    }
   },
   "cell_type": "code",
   "source": "run_paired_ttest(data, \"cost\")",
   "id": "8d3afcd45613ebed",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:52:48.203540Z",
     "start_time": "2024-04-09T10:52:48.191932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_subs = len(data.subject.unique())\n",
    "stats = data.groupby([\"hemisphere\", \"method\"])[[\"max_array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]].mean().reset_index()\n",
    "stats[\"total_subjects\"] = total_subs\n",
    "stats[\"total_dice_loss\"] = 1 - stats[\"total_dice\"]\n",
    "stats[\"array_yield_loss\"] = 1 - stats[\"array_yield\"]\n",
    "column_order = [\"method\", \"hemisphere\", \"max_array\", \"total_subjects\",  \"total_dice_loss\", \"prop_total_dice\", \"array_yield_loss\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "stats = stats[column_order]"
   ],
   "id": "c60f47297470023c",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:52:56.333903Z",
     "start_time": "2024-04-09T10:52:56.322292Z"
    }
   },
   "cell_type": "code",
   "source": "round(stats, 2)",
   "id": "35b6ff065a7de718",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T16:59:21.065499Z",
     "start_time": "2024-04-10T16:59:20.263416Z"
    }
   },
   "cell_type": "code",
   "source": "create_histograms(data)",
   "id": "e3806b35e1f34514",
   "execution_count": 22,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
