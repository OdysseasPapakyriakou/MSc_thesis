{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:28:47.575080Z",
     "start_time": "2024-04-20T09:28:47.551277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ],
   "id": "f33266f57897bf52",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:31:36.174576Z",
     "start_time": "2024-04-20T09:31:36.169556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize(results_df: pd.DataFrame):\n",
    "    total_observations = len(results_df.subject.unique())\n",
    "    res_df = results_df.copy()\n",
    "    res_df[\"total_dice_loss\"] = 1 - res_df[\"total_dice\"]\n",
    "    res_df[\"array_yield_loss\"] = 1 - res_df[\"array_yield\"]\n",
    "    dvs = [\"cost\", \"total_dice_loss\", \"array_yield_loss\", \"total_HD\"]\n",
    "    dv_names = [\"Cost\", \"Dice loss (1-dice)\", \"Yield loss (1-yield)\", \"Hellinger distance\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 6), sharex=True)\n",
    "    for i, dv in enumerate(dvs):\n",
    "        sns.pointplot(x=\"array\", y=dv, hue=\"hemisphere\", data=res_df, ax=axes[i])\n",
    "        axes[i].set_title(f\"Cumulative {dv_names[i].lower()}\", fontsize=16)\n",
    "        axes[i].set_xlabel(\"\", fontsize=16)\n",
    "        axes[i].set_ylabel(dv_names[i], fontsize=16)\n",
    "        axes[i].legend(title=\"Hemisphere\")\n",
    "    fig.suptitle(f\"Mean cumulative losses\", fontsize=24) #based on a total of {total_observations}\n",
    "    fig.supxlabel(\"Array\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./losses.png\")\n",
    "    plt.show()"
   ],
   "id": "107bd50c536f023a",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:31:51.013480Z",
     "start_time": "2024-04-20T09:31:51.009349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data_hem(max_arrays: int):\n",
    "    \"\"\"        \n",
    "    Returns\n",
    "    -------\n",
    "    out_df : pd.DataFrame\n",
    "        A dataframe to be put in the AnovaRM function with columns:\n",
    "        [\"subject\", \"hemisphere\", \"array\", \"total_dice\", \"prop_total_dice\", \n",
    "        \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "    \"\"\"\n",
    "\n",
    "    results_path = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/5_arrays_10x10x10/results/\"   \n",
    "    sub_list = os.listdir(results_path)\n",
    "    out_df = pd.DataFrame()\n",
    "    arrays = [i for i in range(1, max_arrays + 1)]\n",
    "    for sub in sub_list:\n",
    "        if \"exp\" in sub_list:\n",
    "            sub_list.remove(\"exp\")\n",
    "        if \"fsaverage\" in sub_list:\n",
    "            sub_list.remove(\"fsaverage\")\n",
    "        # hem_df = pd.DataFrame()\n",
    "        # both_hems = 0\n",
    "        for hem in [\"LH\", \"RH\"]:\n",
    "            hem_dir = os.path.join(results_path, sub, hem)\n",
    "            filenames = glob.glob(os.path.join(hem_dir, \"*.csv\"))\n",
    "            # Assuming there's only one file in the directory, you can take the first one\n",
    "            filename = [file for file in filenames if \"best\" in file][0]\n",
    "            try:\n",
    "                res_df = pd.read_csv(filename)\n",
    "                columns_to_select = [\"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                max_array_exists = arrays[-1] in res_df[\"array\"].tolist()\n",
    "                if max_array_exists:\n",
    "                    # both_hems += 1\n",
    "                    for array in arrays:\n",
    "                        arr_row = res_df[res_df[\"array\"] == array]\n",
    "                        selected_columns = arr_row[columns_to_select].copy()\n",
    "                        selected_columns[\"subject\"] = sub\n",
    "                        selected_columns[\"hemisphere\"] = hem\n",
    "                        column_order = [\"subject\", \"hemisphere\", \"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                        selected_columns = selected_columns[column_order]\n",
    "                        out_df = pd.concat([out_df, selected_columns], ignore_index=True)\n",
    "                # if both_hems == 2:\n",
    "                #     out_df = pd.concat((out_df, hem_df), ignore_index=True)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"File {filename} not found\")\n",
    "                continue\n",
    "\n",
    "    return out_df"
   ],
   "id": "10eb6acb06d084a3",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:31:51.461283Z",
     "start_time": "2024-04-20T09:31:51.456684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data(max_arrays: int):\n",
    "    \"\"\"        \n",
    "    Returns\n",
    "    -------\n",
    "    out_df : pd.DataFrame\n",
    "        A dataframe to be put in the AnovaRM function with columns:\n",
    "        [\"subject\", \"hemisphere\", \"array\", \"total_dice\", \"prop_total_dice\", \n",
    "        \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "    \"\"\"\n",
    "\n",
    "    results_path = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/5_arrays_10x10x10/results/\"   \n",
    "    sub_list = os.listdir(results_path)\n",
    "    out_df = pd.DataFrame()\n",
    "    arrays = [i for i in range(1, max_arrays + 1)]\n",
    "    for sub in sub_list:\n",
    "        if \"exp\" in sub_list:\n",
    "            sub_list.remove(\"exp\")\n",
    "        if \"fsaverage\" in sub_list:\n",
    "            sub_list.remove(\"fsaverage\")\n",
    "        hem_df = pd.DataFrame()\n",
    "        both_hems = 0\n",
    "        for hem in [\"LH\", \"RH\"]:\n",
    "            hem_dir = os.path.join(results_path, sub, hem)\n",
    "            filenames = glob.glob(os.path.join(hem_dir, \"*.csv\"))\n",
    "            # Assuming there's only one file in the directory, you can take the first one\n",
    "            filename = [file for file in filenames if \"best\" in file][0]\n",
    "            try:\n",
    "                res_df = pd.read_csv(filename)\n",
    "                columns_to_select = [\"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                max_array_exists = arrays[-1] in res_df[\"array\"].tolist()\n",
    "                if max_array_exists:\n",
    "                    both_hems += 1\n",
    "                    for array in arrays:\n",
    "                        arr_row = res_df[res_df[\"array\"] == array]\n",
    "                        selected_columns = arr_row[columns_to_select].copy()\n",
    "                        selected_columns[\"subject\"] = sub\n",
    "                        selected_columns[\"hemisphere\"] = hem\n",
    "                        column_order = [\"subject\", \"hemisphere\", \"array\", \"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "                        selected_columns = selected_columns[column_order]\n",
    "                        hem_df = pd.concat([hem_df, selected_columns], ignore_index=True)\n",
    "                if both_hems == 2:\n",
    "                    out_df = pd.concat((out_df, hem_df), ignore_index=True)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"File {filename} not found\")\n",
    "                continue\n",
    "\n",
    "    return out_df"
   ],
   "id": "e410c15d45558025",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:32:02.836263Z",
     "start_time": "2024-04-20T09:31:55.488878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# these only have the subs that have completed max array in BOTH hemispheres\n",
    "array1_data = get_data(max_arrays=1)\n",
    "array2_data = get_data(max_arrays=2)\n",
    "array3_data = get_data(max_arrays=3)\n",
    "array4_data = get_data(max_arrays=4)\n",
    "all_arrays_data = get_data(max_arrays=5)\n",
    "list_all_array_dfs = [array1_data, array2_data, array3_data, array4_data, all_arrays_data]"
   ],
   "id": "c60f47297470023c",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:32:08.379530Z",
     "start_time": "2024-04-20T09:32:02.837143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# these can have different number of subs for each max array per hemisphere\n",
    "hem_array1_data = get_data_hem(max_arrays=1)\n",
    "hem_array2_data = get_data_hem(max_arrays=2)\n",
    "hem_array3_data = get_data_hem(max_arrays=3)\n",
    "hem_array4_data = get_data_hem(max_arrays=4)\n",
    "all_hem_arrays_data = get_data_hem(max_arrays=5)\n",
    "list_all_hem_array_dfs = [hem_array1_data, hem_array2_data, hem_array3_data, hem_array4_data, all_hem_arrays_data]"
   ],
   "id": "7c84fc24b57baadd",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:32:08.383827Z",
     "start_time": "2024-04-20T09:32:08.380278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_descriptive_stats(all_arrays_df: list, hem: str):\n",
    "    descriptive_stats_df = pd.DataFrame()\n",
    "    for df in all_arrays_df:\n",
    "        hem_df = df[df[\"hemisphere\"] == hem]\n",
    "        max_array = hem_df.array.max()\n",
    "        total_subs = len(hem_df.subject.unique())\n",
    "        stats = hem_df.groupby([\"hemisphere\", \"array\"])[[\"total_dice\", \"prop_total_dice\", \"array_yield\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]].mean().reset_index()\n",
    "        stats = stats[stats[\"array\"] == max_array].reset_index(drop=True)\n",
    "        stats[\"total_subjects\"] = total_subs\n",
    "        stats[\"total_dice_loss\"] = 1 - stats[\"total_dice\"]\n",
    "        stats[\"array_yield_loss\"] = 1 - stats[\"array_yield\"]\n",
    "        column_order = [\"array\", \"total_subjects\", \"hemisphere\",  \"total_dice_loss\", \"prop_total_dice\", \"array_yield_loss\", \"total_HD\", \"prop_total_hd\", \"cost\", \"prop_cost\"]\n",
    "        stats = stats[column_order]\n",
    "        descriptive_stats_df = pd.concat([descriptive_stats_df, stats], ignore_index=True)\n",
    "    \n",
    "    return descriptive_stats_df"
   ],
   "id": "6ce2d4bcbb803b42",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:32:08.424267Z",
     "start_time": "2024-04-20T09:32:08.385133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "descriptives_LH = get_descriptive_stats(list_all_array_dfs, \"LH\")\n",
    "descriptives_RH = get_descriptive_stats(list_all_array_dfs, \"RH\")"
   ],
   "id": "f87c2b41bd6c48c1",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:04:52.473062Z",
     "start_time": "2024-04-09T12:04:52.466959Z"
    }
   },
   "cell_type": "code",
   "source": "descriptives_LH",
   "id": "b1d7decbfec028fd",
   "execution_count": 57,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:04:55.779023Z",
     "start_time": "2024-04-09T12:04:55.773019Z"
    }
   },
   "cell_type": "code",
   "source": "descriptives_RH",
   "id": "9f311d13501947a9",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:05:00.039439Z",
     "start_time": "2024-04-09T12:05:00.011404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "descriptives_hem_LH = get_descriptive_stats(list_all_hem_array_dfs, \"LH\")\n",
    "descriptives_hem_RH = get_descriptive_stats(list_all_hem_array_dfs, \"RH\")"
   ],
   "id": "90e50260e0482540",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:28:08.402506Z",
     "start_time": "2024-04-09T12:28:08.395587Z"
    }
   },
   "cell_type": "code",
   "source": "round(descriptives_hem_LH, 2)",
   "id": "fdc24566027862f8",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:28:05.855303Z",
     "start_time": "2024-04-09T12:28:05.847537Z"
    }
   },
   "cell_type": "code",
   "source": "round(descriptives_hem_RH, 2)",
   "id": "f80b9199daa21de2",
   "execution_count": 70,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T09:32:15.370211Z",
     "start_time": "2024-04-20T09:32:14.076755Z"
    }
   },
   "cell_type": "code",
   "source": "visualize(all_hem_arrays_data)",
   "id": "d42e377dcdc5aa2a",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T14:16:58.644889Z",
     "start_time": "2024-04-07T14:16:58.635904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arr_df = all_arrays_data[(all_arrays_data[\"array\"] == 2) & (all_arrays_data[\"hemisphere\"] == \"LH\")].reset_index(drop=True)\n",
    "cost_std = arr_df[\"cost\"].std()\n",
    "arr_df[\"std_cost\"] = (arr_df[\"cost\"] - arr_df[\"cost\"].mean()) / cost_std\n",
    "arr_df"
   ],
   "id": "6cee5dd991bb6f84",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:16.374190Z",
     "start_time": "2024-04-09T12:42:16.370553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_hem_arrays_data_LH = all_hem_arrays_data[all_hem_arrays_data[\"hemisphere\"] == \"LH\"]\n",
    "all_hem_arrays_data_RH = all_hem_arrays_data[all_hem_arrays_data[\"hemisphere\"] == \"RH\"]"
   ],
   "id": "c4a89381e29cc166",
   "execution_count": 73,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:22.070425Z",
     "start_time": "2024-04-09T12:42:22.065879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_histograms(all_arrays_data_LH, all_arrays_data_RH):\n",
    "    row = 0\n",
    "    col = 0\n",
    "    colors = [\"green\", \"skyblue\", \"olive\", \"gold\", \"teal\"]\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 8))\n",
    "    for hem, df in zip([\"left\", \"right\"], [all_arrays_data_LH, all_arrays_data_RH]):\n",
    "        for arr in range(1, 6):\n",
    "            arr_df = df[df[\"array\"] == arr].reset_index(drop=True).copy()\n",
    "            sns.histplot(data=arr_df, x=\"cost\", kde=False, color=colors[col], ax=axes[row, col])\n",
    "            axes[row, col].set_xlabel(f\"Cost for array {arr}\", fontsize=14) if row == 1 else axes[row, col].set_xlabel(\"\")\n",
    "            axes[row, col].set_ylabel(\"\")\n",
    "            col += 1\n",
    "        row += 1\n",
    "        col = 0\n",
    "    \n",
    "    labels = [\"Count for left hemisphere\", \"Count for right hemisphere\"]\n",
    "    for l, ax in zip(labels, axes):\n",
    "        ax[0].set_ylabel(l, fontsize=14)\n",
    "        \n",
    "    fig.suptitle(f\"Distribution of cost per array and hemisphere\", fontsize=24)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./histograms.png\")\n",
    "    plt.show()"
   ],
   "id": "c7d301c157ed3f75",
   "execution_count": 75,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:42:23.867447Z",
     "start_time": "2024-04-09T12:42:22.718666Z"
    }
   },
   "cell_type": "code",
   "source": "create_histograms(all_hem_arrays_data_LH, all_hem_arrays_data_RH)",
   "id": "e3806b35e1f34514",
   "execution_count": 76,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:16:26.737705Z",
     "start_time": "2024-04-09T12:16:26.733366Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e9e3b7e643f69858",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:17:02.049628Z",
     "start_time": "2024-04-09T12:17:02.039042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for arr in range(1, 6):\n",
    "    for arr_next in range(arr+1, 6):\n",
    "        arr_df_first = all_hem_arrays_data_LH[all_hem_arrays_data_LH[\"array\"] == arr].reset_index(drop=True)\n",
    "        arr_df_second = all_hem_arrays_data_LH[all_hem_arrays_data_LH[\"array\"] == arr_next].reset_index(drop=True)\n",
    "        \n",
    "        arr_df_second[\"dif\"] = arr_df_first[\"cost\"] - arr_df_second[\"cost\"]\n",
    "        dif_std = arr_df_second[\"dif\"].std()\n",
    "        \n",
    "        print(\"Array pair:\", arr, arr_next)\n",
    "        print(\"mean dif and srd:\", round(arr_df_second[\"dif\"].mean(), 4), round(dif_std, 4))"
   ],
   "id": "1b7e1418200c45da",
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:18:30.829467Z",
     "start_time": "2024-04-09T12:18:30.816927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for arr in range(1, 6):\n",
    "    for arr_next in range(arr+1, 6):\n",
    "        arr_df_first = all_hem_arrays_data_RH[all_hem_arrays_data_RH[\"array\"] == arr].reset_index(drop=True)\n",
    "        arr_df_second = all_hem_arrays_data_RH[all_hem_arrays_data_RH[\"array\"] == arr_next].reset_index(drop=True)\n",
    "        \n",
    "        arr_df_second[\"dif\"] = arr_df_first[\"cost\"] - arr_df_second[\"cost\"]\n",
    "        dif_std = arr_df_second[\"dif\"].std()\n",
    "        \n",
    "        print(\"Array pair:\", arr, arr_next)\n",
    "        print(\"mean dif and srd:\", round(arr_df_second[\"dif\"].mean(), 4), round(dif_std, 4))"
   ],
   "id": "514a13a16dd059a3",
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:13:02.467872Z",
     "start_time": "2024-04-09T12:13:02.146512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def post_hoc_comparisons(array_hem_data: pd.DataFrame):\n",
    "    \"\"\"Runs all post-hoc comparisons with Tukey's pairwise test.\n",
    "    This inherently corrects for multiple comparisons, thus\n",
    "    keeping the family-wise error rate at the specified alpha.\n",
    "    \n",
    "    The comparisons are done for the specified hemisphere.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array_data : pd.DataFrame\n",
    "        The dataframe with the results data for one hemisphere.\n",
    "        Columns: [\"subject\", \"hemisphere\", \"array\", \"total_dice\", \"total_yield\", \"total_HD\", \"cost\"]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results : A TukeyHSDResults instance\n",
    "    \"\"\"\n",
    "    results = pairwise_tukeyhsd(endog=array_hem_data[[\"cost\"]],\n",
    "                                groups=array_hem_data[[\"array\"]], alpha=0.05)\n",
    "    \n",
    "    return results\n",
    "\n",
    "for hem in [\"LH\", \"RH\"]:\n",
    "    hem_df = all_hem_arrays_data[all_hem_arrays_data[\"hemisphere\"] == hem]\n",
    "    total_observations = len(hem_df.subject.unique())\n",
    "    print(f\"COMPARISONS FOR {hem}, AND A TOTAL OF 5 ARRAYS WITH {total_observations} SUBJECTS:\")\n",
    "    print(post_hoc_comparisons(hem_df).summary())\n",
    "    print(\"*\"*52, \"\\n\")"
   ],
   "id": "c5837c8d7db33fb6",
   "execution_count": 66,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:34:37.990861Z",
     "start_time": "2024-04-09T12:34:37.572023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pingouin as pg\n",
    "\n",
    "s_LH = pg.sphericity(data=all_hem_arrays_data_LH, dv=\"cost\", subject=\"subject\", within=\"array\")\n",
    "s_RH = pg.sphericity(data=all_hem_arrays_data_RH, dv=\"cost\", subject=\"subject\", within=\"array\")\n",
    "\n",
    "# p val should be > 0.05\n",
    "print(s_LH)\n",
    "print(s_RH)\n",
    "\n",
    "# Homogeneity of variances\n",
    "homogeneity_test_LH = pg.homoscedasticity(all_hem_arrays_data_LH, dv=\"cost\", group=\"array\")\n",
    "homogeneity_test_RH = pg.homoscedasticity(all_hem_arrays_data_RH, dv=\"cost\", group=\"array\")\n",
    "print(\"Homogeneity of variances LH:\\n\", homogeneity_test_LH)\n",
    "print(\"Homogeneity of variances RH:\\n\", homogeneity_test_RH)"
   ],
   "id": "6bfa99c30e8ab49a",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:46:52.392070Z",
     "start_time": "2024-04-09T11:46:51.380704Z"
    }
   },
   "cell_type": "code",
   "source": "visualize(all_arrays_data)",
   "id": "3341fdc62f623721",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:45:43.129695Z",
     "start_time": "2024-04-09T11:45:43.126256Z"
    }
   },
   "cell_type": "code",
   "source": "len(all_hem_arrays_data_LH.subject.unique())",
   "id": "df178e714889ccd3",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:45:43.750710Z",
     "start_time": "2024-04-09T11:45:43.747058Z"
    }
   },
   "cell_type": "code",
   "source": "len(all_hem_arrays_data_RH.subject.unique())",
   "id": "9cae81d2c2185e0b",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:45:45.070334Z",
     "start_time": "2024-04-09T11:45:45.062073Z"
    }
   },
   "cell_type": "code",
   "source": "all_hem_arrays_data_LH",
   "id": "cc89be9731f9f194",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "9aef2b3d429838da",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:45:48.458170Z",
     "start_time": "2024-04-09T11:45:48.393402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_LH = AnovaRM(data=all_hem_arrays_data_LH, depvar=\"cost\", subject=\"subject\",\n",
    "                    within=[\"array\"]).fit()\n",
    "\n",
    "model_RH = AnovaRM(data=all_hem_arrays_data_RH, depvar=\"cost\", subject=\"subject\", within=[\"array\"]).fit()\n",
    "\n",
    "print(model_LH.summary())\n",
    "print(model_RH.summary())"
   ],
   "id": "a21423e95e9866c4",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:44:47.734008Z",
     "start_time": "2024-04-09T11:44:47.727315Z"
    }
   },
   "cell_type": "code",
   "source": "all_arrays_data_LH",
   "id": "b56097256ea37331",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T11:44:35.889709Z",
     "start_time": "2024-04-09T11:44:35.801312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_LH = AnovaRM(data=all_arrays_data_LH, depvar=\"cost\", subject=\"subject\",\n",
    "                    within=[\"array\"]).fit()\n",
    "\n",
    "model_RH = AnovaRM(data=all_arrays_data_RH, depvar=\"cost\", subject=\"subject\", within=[\"array\"]).fit()\n",
    "\n",
    "print(model_LH.summary())\n",
    "print(model_RH.summary())"
   ],
   "id": "61cdcd736f5469e5",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T17:41:44.866924Z",
     "start_time": "2024-04-07T17:41:44.747031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AnovaRM(data=all_arrays_data, depvar=\"cost\", subject=\"subject\", within=[\"array\", \"hemisphere\"]).fit()\n",
    "\n",
    "model.summary()"
   ],
   "id": "60472013ee99a9e5",
   "execution_count": 105,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T18:14:03.983573Z",
     "start_time": "2024-04-06T18:14:03.975851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bioinfokit.analys import stat\n",
    "\n",
    "\"\"\"p needs to be > 0.05 to reject the null, and to infer equal variances\"\"\"\n",
    "res = stat()\n",
    "res.levene(df=all_arrays_data, res_var=\"cost\", xfac_var=\"array\")\n",
    "res.levene_summary"
   ],
   "id": "f716b4f70ebaf545",
   "execution_count": 86,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T18:45:50.203322Z",
     "start_time": "2024-04-06T18:45:50.069723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AnovaRM(data=all_arrays_data, depvar=\"cost\", subject=\"subject\",\n",
    "                    within=[\"array\", \"hemisphere\"]).fit()\n",
    "model.summary()"
   ],
   "id": "71d0ebc156d1c4ca",
   "execution_count": 90,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T19:23:06.426003Z",
     "start_time": "2024-04-06T19:23:05.591379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_rm_anova(array_data: pd.DataFrame):\n",
    "    \"\"\"Runs a repeated measures anova for the given data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array_data : pd.DataFrame\n",
    "        The dataframe with the results data.\n",
    "        Columns: [\"subject\", \"hemisphere\", \"array\", \"total_dice\", \"total_yield\", \"total_HD\", \"cost\"]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : An AnovaRM instance\n",
    "    \"\"\"\n",
    "    model = AnovaRM(data=array_data, depvar=\"cost\", subject=\"subject\",\n",
    "                    within=[\"hemisphere\", \"array\"]).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "for i, array_data in enumerate([array2_data, array3_data, array4_data, all_arrays_data]):\n",
    "    total_observations = len(array_data.subject.unique())\n",
    "    print(f\"RM ANOVA FOR A TOTAL OF {i+2} ARRAYS WITH {total_observations} SUBJECTS:\")\n",
    "    print(run_rm_anova(array_data).summary())\n",
    "    print(\"*\"*52, \"\\n\")"
   ],
   "id": "3c0034972ab66ae0",
   "execution_count": 93,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T14:38:57.671875Z",
     "start_time": "2024-04-05T14:38:57.494115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plotting\n",
    "sns.barplot(data=all_arrays_data, x=\"array\", y=\"cost\", hue=\"hemisphere\")\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Arrays\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.ylim(2.2, 2.6)\n",
    "plt.title(\"Cost per array and hemisphere\")\n",
    "plt.show()"
   ],
   "id": "ef4266a8d835247e",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"A significant interaction between hemisphere:array means that the impact of hemisphere changes depending on the array.\n",
    "\n",
    "A non-significant interaction between hemisphere:array suggests that the impact of the hemisphere remains the same across arrays. The effect of one factor (hemisphere) is consistent across different levels of the other factor (array). This suggests that the factors are independent in terms of their effect on the outcome variable (the cost)!\"\"\""
   ],
   "id": "77796f2fad6b3369",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
