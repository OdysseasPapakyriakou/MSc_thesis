{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93b06ef2d79fe64",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "global fig\n",
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "\n",
    "### needed for matrix rotation/translation ect\n",
    "from skopt.utils import use_named_args, cook_initial_point_generator\n",
    "from skopt.space import Integer\n",
    "from skopt import gp_minimize\n",
    "\n",
    "########################\n",
    "### Custom functions ###\n",
    "########################\n",
    "from src.loss_func import DC, get_yield, hellinger_distance\n",
    "from src.phos_elect import create_grid, implant_grid, get_phosphenes\n",
    "### needed for matrix rotation/translation ect\n",
    "from src.ninimplant import get_xyz\n",
    "import src.utils as utils\n",
    "import src.visualizations as visualizations\n",
    "\n",
    "import src.generate_visual_sectors as gvs\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# added because: \"invalid value encountered in True-divide\"\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# determine range of parameters\n",
    "DIM1 = Integer(name='alpha', low=-90, high=90)  # visual degrees\n",
    "DIM2 = Integer(name='beta', low=-15, high=110)  # visual degrees - -15 is probably lowest possible angle, otherwise other hem is in the way if hem = RH -> low = -110, high = 15\n",
    "DIM3 = Integer(name='offset_from_base', low=0, high=40)     # in mm\n",
    "DIMENSIONS = [DIM1, DIM2, DIM3]\n",
    "CONFIG = utils.read_config(\"config.json\")\n",
    "@use_named_args(dimensions=DIMENSIONS)\n",
    "def f(alpha, beta, offset_from_base):\n",
    "    \"\"\"This function encapsulates the electrode placement procedure and returns the cost value by\n",
    "    comparing the resulting phosphene map with the target map. Be the design of skopt, it can\n",
    "    only take the objective function's parameters as arguments, so other variables used within\n",
    "    the function should be defined as global.\n",
    "\n",
    "    * First it creates a grid based on the four parameters.\n",
    "    * Phosphenes are generated based on the grid's contact points,\n",
    "      and their sizes are determined using cortical magnification and spread values.\n",
    "    * These phosphenes are converted into a 2D image representation.\n",
    "      The function then computes the dice coefficient and yield, and calculates\n",
    "      the Hellinger distance between the generated image and a target density.\n",
    "    * The resulting cost is a combination of these factors,\n",
    "      with penalties applied if the grid is invalid.\n",
    "    * The function also handles cases of invalid values and prints diagnostic information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    The decorators @use_named_args allows to call the function without\n",
    "    specifying the parameters, since dimensions is a list with the parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int or float\n",
    "        The calculated cost used by the bayesopt algorithm\n",
    "    \"\"\"\n",
    "    global CONFIG\n",
    "    # global variables defined in main\n",
    "    global start_location, gm_mask, target_density, bin_thresh\n",
    "    # global coordinates and maps from the mri scans defined in main\n",
    "    global good_coords, good_coords_V1, polar_map, ecc_map, sigma_map\n",
    "    # global variables related to the previous array\n",
    "    global iter_count, total_contacts_xyz_moved, valid_grids, overlap_valid_grids\n",
    "    global arr_current, optimized_arrays_from_f_manual\n",
    "    # cost functions\n",
    "    global arr_dices, total_dices, arr_yields, total_yields, arr_HDs, total_HDs, arr_costs, total_costs\n",
    "\n",
    "    grid_valid_overlap = True\n",
    "    penalty = 0.25\n",
    "    new_angle = (float(alpha), float(beta), 0)\n",
    "\n",
    "    # create grid\n",
    "    orig_grid = create_grid(start_location, CONFIG[\"SHANK_LENGTH\"], CONFIG[\"N_CONTACTPOINTS_SHANK\"], CONFIG[\"N_COMBS\"],\n",
    "                            CONFIG[\"N_SHANKS_PER_COMB\"], CONFIG[\"SPACING_ALONG_XY\"], offset_from_origin=0)\n",
    "\n",
    "    # implanting grid\n",
    "    all_output = implant_grid(gm_mask, orig_grid, start_location, new_angle, offset_from_base)\n",
    "    cur_contacts_xyz_moved, grid_valid_convex_hull = all_output[1], all_output[-1]\n",
    "\n",
    "    if arr_current <= 1:\n",
    "        new_contacts_xyz_moved = cur_contacts_xyz_moved\n",
    "        grid_valid = grid_valid_convex_hull\n",
    "    else:\n",
    "        new_contacts_xyz_moved = np.hstack((total_contacts_xyz_moved, cur_contacts_xyz_moved))\n",
    "        grid_valid_overlap = utils.get_overlap_validity(optimized_arrays_from_f_manual, cur_contacts_xyz_moved, CONFIG)\n",
    "        grid_valid = grid_valid_overlap and grid_valid_convex_hull\n",
    "\n",
    "    overlap_valid_grids.append(grid_valid_overlap)\n",
    "    valid_grids.append(grid_valid)\n",
    "\n",
    "    # get angle, ecc and rfsize for contactpoints (phosphenes[0-2][:] 0 angle x 1 ecc x 2 rfsize)\n",
    "    new_phosphenes_V1 = get_phosphenes(new_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "    array_phosphenes_V1 = get_phosphenes(cur_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "\n",
    "    phosphene_map = utils.get_phosphene_map(new_phosphenes_V1, CONFIG)\n",
    "    phosphene_map_array = utils.get_phosphene_map(array_phosphenes_V1, CONFIG)\n",
    "\n",
    "    # compute dice coefficient -> should be 1 -> invert cost\n",
    "    dice, im1, im2 = DC(target_density, phosphene_map_array, bin_thresh)\n",
    "    par1 = 1.0 - (CONFIG[\"A\"] * dice)\n",
    "    arr_dices.append(dice)\n",
    "\n",
    "    total_dice, _, _ = DC(target_density, phosphene_map, bin_thresh)\n",
    "    par1_total = 1.0 - (CONFIG[\"A\"] * total_dice)\n",
    "    total_dices.append(total_dice)\n",
    "\n",
    "    # compute yield -> should be 1 -> invert cost\n",
    "    grid_yield = get_yield(cur_contacts_xyz_moved, good_coords)\n",
    "\n",
    "    grid_yield_total = get_yield(new_contacts_xyz_moved, good_coords)\n",
    "    total_yields.append(grid_yield_total)\n",
    "\n",
    "    # compute hellinger distance -> should be small -> keep cost\n",
    "    hell_d = hellinger_distance(phosphene_map_array.flatten(), target_density.flatten())\n",
    "    hell_d_total = hellinger_distance(phosphene_map.flatten(), target_density.flatten())\n",
    "\n",
    "    if np.isnan(phosphene_map_array).any() or np.sum(phosphene_map_array) == 0:\n",
    "        par1 = 1\n",
    "\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if dice == 0.0 or np.isnan(phosphene_map).any() or np.sum(phosphene_map) == 0:\n",
    "        par1_total = 1\n",
    "\n",
    "    if np.isnan(hell_d) or np.isinf(hell_d):\n",
    "        par3 = 1\n",
    "    else:\n",
    "        par3 = CONFIG[\"C\"] * hell_d\n",
    "\n",
    "    if dice == 0 or par3 == 1:\n",
    "        grid_yield = 0\n",
    "    par2 = 1.0 - (CONFIG[\"B\"] * grid_yield)\n",
    "    arr_yields.append(grid_yield)\n",
    "\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if hell_d == 1.0 or np.isnan(hell_d_total) or np.isinf(hell_d_total):\n",
    "        par3_total = 1\n",
    "    else:\n",
    "        par3_total = CONFIG[\"C\"] * hell_d_total\n",
    "\n",
    "    arr_HDs.append(hell_d)\n",
    "    total_HDs.append(hell_d_total)\n",
    "\n",
    "    # combine cost functions\n",
    "    cost = par1 + par2 + par3\n",
    "    cost_total = par1_total + par2 + par3_total\n",
    "\n",
    "    # when some contact points are outside of the hemisphere (convex), add penalty\n",
    "    if not grid_valid:\n",
    "        cost = par1 + penalty + par2 + penalty + par3 + penalty\n",
    "        # always include the array specific yield\n",
    "        cost_total = par1_total + penalty + par2 + penalty + par3_total + penalty\n",
    "\n",
    "    # check if cost contains invalid value\n",
    "    if np.isnan(cost) or np.isinf(cost):\n",
    "        cost = 3\n",
    "\n",
    "    if np.isnan(cost_total) or np.isinf(cost_total):\n",
    "        cost_total = 3\n",
    "\n",
    "    arr_costs.append(cost)\n",
    "    total_costs.append(cost_total)\n",
    "\n",
    "    print(f\"overlap valid: {grid_valid_overlap} / convex hull valid: {grid_valid_convex_hull} / \"\n",
    "          f\"cost: {cost} / total cost: {cost_total}\")\n",
    "    print(f\"dice: {round(dice, 5)} / total dice: {round(total_dice, 5)} / yield: {round(grid_yield, 5)} / \"\n",
    "          f\"total yield: {round(grid_yield_total, 5)} / HD: {round(par3, 5)} / total HD: {round(par3_total, 5)}\", end=\"\\n\")\n",
    "\n",
    "    iter_count += 1\n",
    "    if iter_count % 25 == 0:\n",
    "        print(\"Now at iteration:\", iter_count, \"out of\", CONFIG[\"NUM_CALLS\"])\n",
    "\n",
    "    return cost_total\n",
    "\n",
    "\n",
    "def f_manual(alpha, beta, offset_from_base, good_coords, good_coords_V1, target_density):\n",
    "    \"\"\"\n",
    "    Copy from f, to get phosphene map and contact points for the optimized parameters. Used to visualize results.\n",
    "    \"\"\"\n",
    "    global CONFIG\n",
    "    # global variables defined in main\n",
    "    global start_location, gm_mask, bin_thresh\n",
    "    # global coordinates and maps from the mri scans defined in main\n",
    "    global polar_map, ecc_map, sigma_map\n",
    "    # global variables related to the previous array\n",
    "    global iter_count, total_contacts_xyz_moved\n",
    "    global arr_current, optimized_arrays_from_f_manual\n",
    "    global best_dc, best_hd\n",
    "\n",
    "    penalty = 0.25\n",
    "    new_angle = (float(alpha), float(beta), 0)\n",
    "\n",
    "    # create grid\n",
    "    orig_grid = create_grid(start_location, CONFIG[\"SHANK_LENGTH\"], CONFIG[\"N_CONTACTPOINTS_SHANK\"], CONFIG[\"N_COMBS\"],\n",
    "                            CONFIG[\"N_SHANKS_PER_COMB\"], CONFIG[\"SPACING_ALONG_XY\"], offset_from_origin=0)\n",
    "\n",
    "    # implanting grid\n",
    "    ref_contacts_xyz, best_contacts_xyz_moved, refline, refline_moved, projection, ref_orig, ray_visualize, new_location, grid_valid_convex_hull = implant_grid(\n",
    "        gm_mask, orig_grid, start_location, new_angle, offset_from_base)\n",
    "\n",
    "    if arr_current <= 1:\n",
    "        new_contacts_xyz_moved = best_contacts_xyz_moved\n",
    "        grid_valid = grid_valid_convex_hull\n",
    "    else:\n",
    "        new_contacts_xyz_moved = np.hstack((total_contacts_xyz_moved, best_contacts_xyz_moved))\n",
    "        grid_valid_overlap = utils.get_overlap_validity(optimized_arrays_from_f_manual, best_contacts_xyz_moved, CONFIG)\n",
    "        grid_valid = grid_valid_overlap and grid_valid_convex_hull\n",
    "\n",
    "    # get angle, ecc and rfsize for contactpoints in each ROI (phosphenes[0-2][:] 0 angle x 1 ecc x 2 rfsize)\n",
    "    new_phosphenes_V1 = get_phosphenes(new_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "    array_phosphenes_V1 = get_phosphenes(best_contacts_xyz_moved, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "\n",
    "    phosphene_map = utils.get_phosphene_map(new_phosphenes_V1, CONFIG)\n",
    "    phosphene_map_array = utils.get_phosphene_map(array_phosphenes_V1, CONFIG)\n",
    "\n",
    "    # compute dice coefficient -> should be large -> invert cost\n",
    "    arr_dice, im1, im2 = DC(target_density, phosphene_map_array, bin_thresh)\n",
    "\n",
    "    if not grid_valid or arr_dice == 0.0:\n",
    "        return [grid_valid, arr_dice]\n",
    "\n",
    "    total_dice, _, _ = DC(target_density, phosphene_map, bin_thresh)\n",
    "    par1_total = 1.0 - (CONFIG[\"A\"] * total_dice)\n",
    "\n",
    "    prop_total_dice = total_dice / best_dc\n",
    "\n",
    "    # compute yield -> should be 1 -> invert cost\n",
    "    arr_yield = get_yield(best_contacts_xyz_moved, good_coords)\n",
    "    total_yield = get_yield(new_contacts_xyz_moved, good_coords)\n",
    "\n",
    "    # compute Hellinger distance -> should be small -> keep cost\n",
    "    arr_hd = hellinger_distance(phosphene_map_array.flatten(), target_density.flatten())\n",
    "    total_hd = hellinger_distance(phosphene_map.flatten(), target_density.flatten())\n",
    "\n",
    "    prop_total_hd = (1 - total_hd) / (1 - best_hd)\n",
    "\n",
    "    ## validations steps\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if arr_dice == 0.0 or np.isnan(phosphene_map).any() or np.sum(phosphene_map) == 0:\n",
    "        par1_total = 1\n",
    "\n",
    "    if np.isnan(arr_hd) or np.isinf(arr_hd):\n",
    "        par3 = 1\n",
    "    else:\n",
    "        par3 = CONFIG[\"C\"] * arr_hd\n",
    "\n",
    "    if arr_dice == 0 or par3 == 1:\n",
    "        arr_yield = 0\n",
    "    par2 = 1.0 - (CONFIG[\"B\"] * arr_yield)\n",
    "\n",
    "    ####### added the first conditional to prevent lower cost functions for empty array #######\n",
    "    if arr_hd == 1.0 or np.isnan(total_hd) or np.isinf(total_hd):\n",
    "        par3_total = 1\n",
    "    else:\n",
    "        par3_total = CONFIG[\"C\"] * total_hd\n",
    "\n",
    "    # combine cost functions\n",
    "    cost = par1_total + par2 + par3_total\n",
    "    best_cost = best_dc + 0 + best_hd\n",
    "    highest_cost = 3\n",
    "    # when some contact points are outside of the hemisphere (convex), add penalty\n",
    "    if not grid_valid:\n",
    "        cost = par1_total + penalty + par2 + penalty + par3_total + penalty\n",
    "\n",
    "    # check if cost contains invalid value\n",
    "    if np.isnan(cost) or np.isinf(cost):\n",
    "        cost = 3\n",
    "\n",
    "    # the proportion of the cost compared to the best possible cost\n",
    "    prop_cost = 1 - ((cost - best_cost) / (highest_cost - best_cost))\n",
    "\n",
    "    return [grid_valid, arr_dice, total_dice, prop_total_dice, arr_hd, total_hd, prop_total_hd, arr_yield, total_yield,\n",
    "            cost, prop_cost, array_phosphenes_V1, new_phosphenes_V1,\n",
    "            best_contacts_xyz_moved, phosphene_map_array, phosphene_map, new_contacts_xyz_moved]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a506b205ec662444",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"configuration:\\n {CONFIG['N_COMBS']} x {CONFIG['N_SHANKS_PER_COMB']} x {CONFIG['N_CONTACTPOINTS_SHANK']}\")\n",
    "XO = (CONFIG[\"INIT_ALPHA\"], CONFIG[\"INIT_BETA\"], CONFIG[\"INIT_OFFSET_FROM_BASE\"])\n",
    "\n",
    "# set file names\n",
    "FNAME_ANG = \"inferred_angle.mgz\"\n",
    "FNAME_ECC = \"inferred_eccen.mgz\"\n",
    "FNAME_SIGMA = \"inferred_sigma.mgz\"\n",
    "FNAME_APARC = \"aparc+aseg.mgz\"\n",
    "FNAME_LABEL = \"inferred_varea.mgz\"\n",
    "\n",
    "# set beta angle range according to hemisphere\n",
    "dim2_lh = Integer(name=\"beta\", low=-15, high=110)\n",
    "dim2_rh = Integer(name=\"beta\", low=-110, high=15)\n",
    "RESULTS_PATH = \"/home/odysseas/Desktop/UU/thesis/BayesianOpt/16_arrays_1x10x10/results/\"\n",
    "\n",
    "\n",
    "def run(sub):\n",
    "    global start_location, gm_mask, target_density, bin_thresh\n",
    "    global arr_current, total_contacts_xyz_moved, optimized_arrays_from_f_manual\n",
    "    global overlap_valid_grids, valid_grids, iter_count\n",
    "    global good_coords, good_coords_V1, polar_map, ecc_map, sigma_map\n",
    "    # cost functions\n",
    "    global arr_dices, total_dices, arr_yields, total_yields, arr_HDs, total_HDs, arr_costs, total_costs\n",
    "    global best_dc, best_hd\n",
    "\n",
    "    dim1 = Integer(name='alpha', low=-90, high=90)  # visual degrees\n",
    "    dim2 = Integer(name='beta', low=-15,\n",
    "                   high=110)  # visual degrees - -15 is probably lowest possible angle, otherwise other hem is in the way if hem = RH -> low = -110, high = 15\n",
    "    dim3 = Integer(name='offset_from_base', low=0, high=40)  # in mm\n",
    "\n",
    "    target_density = gvs.complete_gauss(windowsize=CONFIG[\"WINDOWSIZE\"],\n",
    "                                        fwhm=1200, radiusLow=0, radiusHigh=500, center=None, plotting=False)\n",
    "\n",
    "    # set beta angle range according to hemisphere\n",
    "    dim2_lh = Integer(name=\"beta\", low=-15, high=110)\n",
    "    dim2_rh = Integer(name=\"beta\", low=-110, high=15)\n",
    "\n",
    "    target_density /= target_density.max()\n",
    "    target_density /= target_density.sum()\n",
    "    bin_thresh = np.percentile(target_density, CONFIG[\"DC_PERCENTILE\"])\n",
    "    data_dir = f\"/home/odysseas/Desktop/UU/thesis/BayesianOpt/input_processed_data_HCP/{sub}/T1w/mri/\"\n",
    "\n",
    "    if sub == \"fsaverage\":\n",
    "        data_dir = \"/media/odysseas/CK1TB_1/Electrode-Placement_Human/HCP/subjects/\" + str(sub) + \"/mri/\"\n",
    "\n",
    "    # actually load data\n",
    "    ang_img = nib.load(data_dir + FNAME_ANG)\n",
    "    polar_map = ang_img.get_fdata()\n",
    "    ecc_img = nib.load(data_dir + FNAME_ECC)\n",
    "    ecc_map = ecc_img.get_fdata()\n",
    "    sigma_img = nib.load(data_dir + FNAME_SIGMA)\n",
    "    sigma_map = sigma_img.get_fdata()\n",
    "    aparc_img = nib.load(data_dir + FNAME_APARC)\n",
    "    aparc_roi = aparc_img.get_fdata()\n",
    "    label_img = nib.load(data_dir + FNAME_LABEL)\n",
    "    label_map = label_img.get_fdata()\n",
    "\n",
    "    # compute valid voxels\n",
    "    dot = (ecc_map * polar_map)\n",
    "    good_coords = np.asarray(np.where(dot != 0.0))\n",
    "\n",
    "    # filter gm per hemisphere\n",
    "    cs_coords_rh = np.where(aparc_roi == 1021)\n",
    "    cs_coords_lh = np.where(aparc_roi == 2021)\n",
    "    gm_coords_rh = np.vstack(np.where((aparc_roi >= 1000) & (aparc_roi < 2000)))\n",
    "    gm_coords_lh = np.vstack(np.where(aparc_roi > 2000))\n",
    "    xl, yl, zl = get_xyz(gm_coords_lh)\n",
    "    xr, yr, zr = get_xyz(gm_coords_rh)\n",
    "    gm_lh = np.array([xl, yl, zl]).T\n",
    "    gm_rh = np.array([xr, yr, zr]).T\n",
    "\n",
    "    # extract labels\n",
    "    v1_coords_rh = np.asarray(np.where(label_map == 1))\n",
    "    v1_coords_lh = np.asarray(np.where(label_map == 1))\n",
    "\n",
    "    set_rounded_good_coords = set(map(tuple, good_coords.T))\n",
    "    set_rounded_gm_coords_rh = set(map(tuple, gm_coords_rh.T))\n",
    "    set_rounded_gm_coords_lh = set(map(tuple, gm_coords_lh.T))\n",
    "    set_rounded_v1_coords_lh = set(map(tuple, v1_coords_lh.T))\n",
    "    set_rounded_v1_coords_rh = set(map(tuple, v1_coords_rh.T))\n",
    "\n",
    "    # divide V1 coords per hemisphere\n",
    "    good_coords_lh = np.array(list(set(set_rounded_good_coords) & set(set_rounded_gm_coords_lh))).T\n",
    "    good_coords_rh = np.array(list(set(set_rounded_good_coords) & set(set_rounded_gm_coords_rh))).T\n",
    "    v1_coords_lh = np.array(list(set(set_rounded_v1_coords_lh) & set(set_rounded_gm_coords_lh))).T\n",
    "    v1_coords_rh = np.array(list(set(set_rounded_v1_coords_rh) & set(set_rounded_gm_coords_rh))).T\n",
    "\n",
    "    # find center of left and right calcarine sulci\n",
    "    median_lh = [np.median(cs_coords_lh[0][:]), np.median(cs_coords_lh[1][:]), np.median(cs_coords_lh[2][:])]\n",
    "    median_rh = [np.median(cs_coords_rh[0][:]), np.median(cs_coords_rh[1][:]), np.median(cs_coords_rh[2][:])]\n",
    "\n",
    "    # get GM mask and compute dorsal/posterior planes\n",
    "    gm_mask = np.where(aparc_roi != 0)\n",
    "\n",
    "    # apply optimization to each hemisphere\n",
    "    for gm_mask, hem, start_location, good_coords, good_coords_V1, dim2 in zip([gm_lh, gm_rh], [\"LH\", \"RH\"],\n",
    "                                                                               [median_lh, median_rh],\n",
    "                                                                               [good_coords_lh, good_coords_rh],\n",
    "                                                                               [v1_coords_lh, v1_coords_rh],\n",
    "                                                                               [dim2_lh, dim2_rh]):\n",
    "\n",
    "        print(f\"SUBJECT {sub}, HEMISPHERE {hem}\")\n",
    "        utils.create_dirs(RESULTS_PATH, sub, hem)\n",
    "\n",
    "        best_possible_phos = get_phosphenes(good_coords_V1, good_coords_V1, polar_map, ecc_map, sigma_map)\n",
    "        best_possible_map = utils.get_phosphene_map(best_possible_phos, CONFIG)\n",
    "\n",
    "        visualizations.visualize_phosphene_maps({}, best_possible_map, RESULTS_PATH, sub, hem, CONFIG, best=True)\n",
    "        visualizations.visualize_polar_plot(best_possible_phos, RESULTS_PATH, sub, hem, CONFIG, best=True)\n",
    "        visualizations.visualize_kde_polar_plot(best_possible_phos, RESULTS_PATH, sub, hem, CONFIG, best=True)\n",
    "\n",
    "        best_dc, _, _ = DC(target_density, best_possible_map, bin_thresh)\n",
    "        best_hd = hellinger_distance(best_possible_map.flatten(), target_density.flatten())\n",
    "\n",
    "        total_contacts_xyz_moved = None\n",
    "        all_phosphenes = None\n",
    "        total_phosphene_map = None\n",
    "        optimized_arrays_from_f_manual = {}\n",
    "        phosphenes_per_arr = {}\n",
    "        phosphene_map_per_arr = {}\n",
    "        out_df_all_results = pd.DataFrame()\n",
    "        out_df_best_results = pd.DataFrame()\n",
    "        dimensions = [dim1, dim2, dim3]\n",
    "        # global arr_current\n",
    "        arr_current = 1\n",
    "        for i in range(1, CONFIG[\"N_ARRAYS\"] + 1):\n",
    "            print(f\"NOW WORKING ON ARRAY {i} OUT OF {CONFIG['N_ARRAYS']} \"\n",
    "                  f\"AND VALID ONES SO FAR ARE {len(optimized_arrays_from_f_manual)}\")\n",
    "\n",
    "            arr_dices, total_dices = [], []\n",
    "            arr_yields, total_yields = [], []\n",
    "            arr_HDs, total_HDs = [], []\n",
    "            arr_costs, total_costs = [], []\n",
    "\n",
    "            iter_count = 1\n",
    "            valid_grids = []\n",
    "            overlap_valid_grids = []\n",
    "\n",
    "            # create initial point generator\n",
    "            lhs2 = cook_initial_point_generator(\"lhs\", criterion=\"maximin\")\n",
    "\n",
    "            # optimize\n",
    "            print(\"Starting iteration: 1\")\n",
    "            res = gp_minimize(f, x0=XO, dimensions=dimensions, n_jobs=1, n_calls=CONFIG[\"NUM_CALLS\"],\n",
    "                              n_initial_points=CONFIG[\"NUM_INITIAL_POINTS\"], initial_point_generator=lhs2,\n",
    "                              callback=[utils.custom_stopper])\n",
    "\n",
    "            # print results\n",
    "            print(\"subject \", sub, \" \", hem)\n",
    "            print(\"best alpha:\", res.x[0])\n",
    "            print(\"best beta:\", res.x[1])\n",
    "            print(\"best offset_from_base:\", res.x[2])\n",
    "\n",
    "            # the final array coordinates are contacts_xyz_moved\n",
    "            data = f_manual(res.x[0], res.x[1], res.x[2], good_coords, good_coords_V1, target_density)\n",
    "            grid_valid, arr_dice = data[0], data[1]\n",
    "\n",
    "            print(f\"The best configuration for array {i} is {'valid' if grid_valid else 'invalid'}\")\n",
    "\n",
    "            if not grid_valid or arr_dice == 0.0:\n",
    "                print(f\"should skip array {i} because it is invalid or phosphene map is empty\")\n",
    "                continue\n",
    "\n",
    "            (total_dice, prop_total_dice, arr_hd, total_hd, prop_total_hd, arr_yield, total_yield,\n",
    "             cost, prop_cost, arr_phosphenes, all_phosphenes, contacts_xyz_moved,\n",
    "             arr_phosphene_map, total_phosphene_map, total_contacts_xyz_moved) = data[2:]\n",
    "\n",
    "            optimized_arrays_from_f_manual[arr_current] = contacts_xyz_moved\n",
    "            phosphenes_per_arr[arr_current] = arr_phosphenes\n",
    "            phosphene_map_per_arr[arr_current] = arr_phosphene_map\n",
    "            print(\"best dice, best total dice, best yield, best total yield, best total cost:\", arr_dice,\n",
    "                  total_dice, arr_yield, total_yield, cost)\n",
    "            print(\"best HD, best total HD:\", arr_hd, total_hd)\n",
    "            print(\"prop total dice, prop total hd, prop cost\", prop_total_dice, prop_total_hd, prop_cost)\n",
    "\n",
    "            visualizations.visualize_array_map(arr_phosphene_map, total_phosphene_map, hem)\n",
    "            print(\"TOTAL VALID GRIDS:\", sum(valid_grids))\n",
    "            print(\"TOTAL OVERLAP VALID GRIDS:\", sum(overlap_valid_grids))\n",
    "            print(\"*\" * 35)\n",
    "            print(\"FINISHED ARRAY\", arr_current)\n",
    "            print(\"*\" * 35)\n",
    "\n",
    "            df_arr = utils.get_arr_df(arr_current, arr_dices, total_dices, arr_yields, total_yields, arr_HDs,\n",
    "                                total_HDs, arr_costs, total_costs, CONFIG[\"NUM_CALLS\"])\n",
    "            df_best = utils.get_best_df(arr_current, arr_dice, total_dice, prop_total_dice, arr_yield, total_yield,\n",
    "                                  arr_hd, total_hd, prop_total_hd, cost, prop_cost, res)\n",
    "\n",
    "            out_df_all_results = pd.concat([out_df_all_results, df_arr], axis=0, ignore_index=True)\n",
    "            out_df_best_results = pd.concat([out_df_best_results, df_best], axis=0, ignore_index=True)\n",
    "            arr_current += 1\n",
    "\n",
    "        # df_final_results = utils.get_final_df(CONFIG[\"N_ARRAYS\"], len(optimized_arrays_from_f_manual), total_dice,\n",
    "        #                                 prop_total_dice, total_yield, total_hd, prop_total_hd, cost, prop_cost, res)\n",
    "        # utils.write_results(df_final_results, RESULTS_PATH, sub, hem, \"final\")\n",
    "        # pickle_data = [optimized_arrays_from_f_manual, phosphenes_per_arr, phosphene_map_per_arr,\n",
    "        #                total_contacts_xyz_moved, all_phosphenes, total_phosphene_map]\n",
    "        # \n",
    "        # utils.write_results(out_df_all_results, RESULTS_PATH, sub, hem, \"all\")\n",
    "        # utils.write_results(out_df_best_results, RESULTS_PATH, sub, hem, \"best\")\n",
    "        # \n",
    "        # utils.write_results_pickle(RESULTS_PATH, sub, hem, pickle_data)\n",
    "        # utils.write_params(RESULTS_PATH, sub, hem)\n",
    "        # \n",
    "        # # visualize and save maps\n",
    "        # visualizations.visualize_phosphene_maps(phosphene_map_per_arr, total_phosphene_map, RESULTS_PATH, sub, hem, CONFIG)\n",
    "        # visualizations.visualize_polar_plot(all_phosphenes, RESULTS_PATH, sub, hem, CONFIG)\n",
    "        # visualizations.visualize_kde_polar_plot(all_phosphenes, RESULTS_PATH, sub, hem, CONFIG)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6b9cb09c5653c01",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "subj_list = [\"exp\", \"100610\", \"100206\", \"fsaverage\", \"757764\", \"118225\", \"144226\", \"162935\"]\n",
    "for sub in subj_list[:1]:\n",
    "    run(sub)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69675acc068fbb5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b91faeca69b9be72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
